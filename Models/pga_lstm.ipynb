{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m_7iKLrVWs13"
   },
   "source": [
    "# **Load Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2202,
     "status": "ok",
     "timestamp": 1568315406218,
     "user": {
      "displayName": "Arka Daw",
      "photoUrl": "",
      "userId": "06797637409844358433"
     },
     "user_tz": 240
    },
    "id": "Vvk51A99WydE",
    "outputId": "57fb69c8-dc69-4aac-d27e-5091b20db713"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "#saving and loading\n",
    "import scipy.io as spio\n",
    "\n",
    "#visualization\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Dropout\n",
    "from keras import backend as K\n",
    "from keras.layers import Bidirectional, TimeDistributed, LSTM\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import h5py\n",
    "from keras.layers import concatenate\n",
    "from keras import regularizers\n",
    "import keras\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.engine import InputSpec\n",
    "\n",
    "import os\n",
    "#from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftzDxoc3XPpR"
   },
   "source": [
    "# **Define Dropout Prediction Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Urre-ZYYXWr8"
   },
   "outputs": [],
   "source": [
    "class KerasDropoutPrediction(object):\n",
    "    def __init__(self ,model):\n",
    "        self.f = K.function(\n",
    "            [model.layers[0].input,\n",
    "             K.learning_phase()],\n",
    "            [model.layers[-1].output])\n",
    "    def predict(self ,x, n_iter=10):\n",
    "        result = []\n",
    "        for _ in range(n_iter):\n",
    "            result.append(self.f([x , 1]))\n",
    "        result = np.array(result).reshape(n_iter ,x.shape[0] ,x.shape[1]).T\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zF_YErPuYGEo"
   },
   "source": [
    "# Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2191,
     "status": "ok",
     "timestamp": 1568315406220,
     "user": {
      "displayName": "Arka Daw",
      "photoUrl": "",
      "userId": "06797637409844358433"
     },
     "user_tz": 240
    },
    "id": "8yrtQ1oiYLSe",
    "outputId": "a005e50c-85f4-4d81-fee2-48bf614ee68d"
   },
   "outputs": [],
   "source": [
    "#drive.mount('/content/gdrive')\n",
    "#os.chdir(\"gdrive/My Drive/Colab Notebooks/Lake Temperature Modelling/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PkL1XwfDY7E_"
   },
   "source": [
    "# Define Custom Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipua1UGhZBAp"
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "\n",
    "def masked_mean_squared_error(y_true ,y_pred):\n",
    "    return K.mean(y_true[:, :, 1] * K.square(y_pred[:, :, 0] - y_true[:, :, 0]), axis=-1)\n",
    "\n",
    "\n",
    "def masked_root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(y_true[:, :, 1] * K.square(y_pred[:, :, 0] - y_true[:, :, 0]), axis=-1))\n",
    "  \n",
    "def combined_loss(params):\n",
    "    udendiff, lam = params\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        return masked_mean_squared_error(y_true, y_pred) + lam * K.mean(K.relu(udendiff))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def phy_loss_mean(params):\n",
    "    # useful for cross-checking training\n",
    "    udendiff, lam = params\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        return K.mean(K.relu(udendiff))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QHvJRlUZLs7"
   },
   "source": [
    "# Density Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOa1HCq9ZS8w"
   },
   "outputs": [],
   "source": [
    "def density(temp):\n",
    "    return np.log10(1 + (1 - (temp + 288.9414) * (temp - 3.9863) ** 2 / (508929.2 * (temp + 68.12963))))\n",
    "    # [math.log(0.1+y) for y in x]\n",
    "    # return y;\n",
    "\n",
    "def actual_density(temp):\n",
    "    return (1 - (temp + 288.9414) * (temp - 3.9863) ** 2 / (508929.2 * (temp + 68.12963)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejUYOzx0Zhmp"
   },
   "source": [
    "# Load the Monotonic LSTM script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFXNtODfZl28"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append(\"/home/karpatne/Documents/Lake Temperature Modelling/Monotonic LSTM Script\")\n",
    "sys.path.append(\"C:\\\\Users\\\\arkad\\\\Documents\\\\Lake Temperature Modelling\\\\Monotonic LSTM Script\")\n",
    "#import final_mLSTM\n",
    "from final_mLSTM import mLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r1l0otQ1dZ8g"
   },
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cjbvy7ZrdmeK"
   },
   "outputs": [],
   "source": [
    "def read_Data():\n",
    "  \n",
    "  #dir='/home/karpatne/Documents/Lake Temperature Modelling/Datasets/';\n",
    "  dir='C:\\\\Users\\\\arkad\\\\Documents\\\\Lake Temperature Modelling\\\\Datasets\\\\'  \n",
    "  if use_temporal_feature==1:\n",
    "      filename = 'temporal_mendota_train_test_split_4_year_train_new.mat';\n",
    "  else:\n",
    "      filename = 'new_data_mendota_train_test_split_4_year_train.mat';\n",
    "  matfile = spio.loadmat(dir + filename, squeeze_me=True,\n",
    "                         variable_names=['train_X','train_Y_glm','train_Y_true','test_X','test_Y_glm','test_Y_true'])\n",
    "\n",
    "  train_X = matfile['train_X'];\n",
    "  train_y = matfile['train_Y_true'];\n",
    "  train_y_glm = matfile['train_Y_glm'];\n",
    "\n",
    "  test_X = matfile['test_X'];\n",
    "  test_y = matfile['test_Y_true'];\n",
    "  test_y_glm = matfile['test_Y_glm'];\n",
    "  params = [train_X,train_y,train_y_glm,test_X,test_y,test_y_glm];\n",
    "  return params;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zfxzxg3ZxtkZ"
   },
   "source": [
    "# Train Subset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BbPGkbox3l_"
   },
   "outputs": [],
   "source": [
    "def train_subset(train_X, train_y, train_y_glm):\n",
    "  \n",
    "  count=np.zeros(train_y.shape[0]);\n",
    "  for i in range(train_y.shape[0]):\n",
    "      count[i]=np.count_nonzero(train_y[i,:,1]);\n",
    "  tot_size=np.sum(count);  \n",
    "  tr_size=tr_frac*tot_size/100;\n",
    "  index=(np.arange(train_y.shape[0])).tolist();\n",
    "  ix=[];\n",
    "  size=0;\n",
    "  while len(index)>0:\n",
    "      temp=index.pop(random.randrange(0,len(index)));\n",
    "      size=size+count[temp];\n",
    "      ix.append(temp);\n",
    "      if size>=tr_size:\n",
    "          break;\n",
    "  ix=np.sort(np.asarray(ix));\n",
    "  train_X=train_X[ix];\n",
    "  train_y=train_y[ix];\n",
    "  train_y_glm=train_y_glm[ix];\n",
    "  params=[ix,train_X,train_y,train_y_glm];\n",
    "  return params;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_YExzswP3Fvj"
   },
   "source": [
    "## 3D to 2D transform matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bO4_0Ff3O64"
   },
   "outputs": [],
   "source": [
    "def transform_3d_to_2d(X):\n",
    "  return X.reshape((X.shape[0]*X.shape[1],X.shape[2]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8mrb1oi3mPL"
   },
   "source": [
    "## 2D to 3D transform matrix using depth steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uKek0XGi31VW"
   },
   "outputs": [],
   "source": [
    "def transform_2d_to_3d(X, steps):\n",
    "  return X.reshape((int(X.shape[0]/steps),steps,X.shape[1]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpEH5vfPBSas"
   },
   "source": [
    "## Masking Output Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaFF5idWBgK9"
   },
   "outputs": [],
   "source": [
    "def masking_output_labels(\n",
    "    y_density,\n",
    "    y_temperature,\n",
    "    mask_value):\n",
    "  \n",
    "  \n",
    "  for i in range(y_density.shape[0]):\n",
    "        if math.isnan(y_density[i, 0]):\n",
    "            y_density[i, 0] = mask_value;\n",
    "            y_temperature[i, 0] = mask_value;\n",
    "  params=[y_density,y_temperature];\n",
    "  return params;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JCvs0nSADOf2"
   },
   "source": [
    "# Edge Padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LVR4hYvDQZE"
   },
   "outputs": [],
   "source": [
    "def edge_padding(\n",
    "    X,\n",
    "    y_density,\n",
    "    y_temperature,\n",
    "    pad_steps):\n",
    "  \n",
    "  \n",
    "  X_pad = np.zeros((X.shape[0], X.shape[1] + pad_steps, X.shape[2]))\n",
    "  y_density_pad = np.zeros((y_density.shape[0], y_density.shape[1] + pad_steps, y_density.shape[2]))\n",
    "  y_temperature_pad = np.zeros((y_temperature.shape[0], y_temperature.shape[1] + pad_steps, y_temperature.shape[2]))\n",
    "  for i in range(X.shape[0]):\n",
    "      X_pad[i, :, :] = np.pad(X[i, :, :], ((pad_steps, 0), (0, 0)), 'edge')\n",
    "      y_density_pad[i, :, :] = np.pad(y_density[i, :, :], ((pad_steps, 0), (0, 0)), 'edge')\n",
    "      y_temperature_pad[i, :, :] = np.pad(y_temperature[i, :, :], ((pad_steps, 0), (0, 0)), 'edge')\n",
    "  params=[X_pad,y_density_pad,y_temperature_pad];\n",
    "  return params;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OUUqrs2rFPC-"
   },
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1bXAWdaFREm"
   },
   "outputs": [],
   "source": [
    "def createModel(\n",
    "        input_shape1,\n",
    "        input_shape2,\n",
    "        lstm_nodes, \n",
    "        lstm_bias, \n",
    "        drop_frac, \n",
    "        feedforward_nodes, \n",
    "        lamda_reg, \n",
    "        n_nodes):\n",
    "  \n",
    "  \n",
    "  main_input=Input(shape=(input_shape1, input_shape2), name='main_input')\n",
    "  #stm1=LSTM(lstm_nodes,return_sequences=True, use_bias=lstm_bias, recurrent_dropout=drop_frac)(main_input)\n",
    "  #dense0=Dense(feedforward_nodes, activation='relu', use_bias=1,\n",
    "  #             kernel_regularizer=regularizers.l1_l2(l1=lamda_reg,l2=lamda_reg))(main_input)\n",
    "  #dropout0=Dropout(drop_frac)(dense0)\n",
    "  mlstm_out=mLSTM(lstm_nodes,return_sequences=True, use_bias=lstm_bias, recurrent_dropout=drop_frac)(main_input)\n",
    "  dense1=TimeDistributed(Dense(feedforward_nodes,use_bias=1,\n",
    "               kernel_regularizer=regularizers.l1_l2(l1=lamda_reg,l2=lamda_reg)))(mlstm_out)\n",
    "  activ_dense1=keras.layers.ELU(alpha=1.0)(dense1)\n",
    "  dropout1=Dropout(drop_frac)(activ_dense1)\n",
    "  #dense2=TimeDistributed(Dense(feedforward_nodes,use_bias=1,kernel_regularizer=regularizers.l1_l2(l1=0.05,l2=0.05)))(dropout1)\n",
    "  #activ_dense2=keras.layers.ELU(alpha=1.0)(dense2)\n",
    "  #dropout2=Dropout(drop_frac)(activ_dense2)\n",
    "  rho_out=TimeDistributed(Dense(1, activation='linear'),name='aux_output')(dropout1)\n",
    "  #auxiliary_input=Input(shape=(aux_train_X.shape[1],aux_train_X.shape[2]),name='aux_input')\n",
    "  x=concatenate([rho_out,main_input])\n",
    "  dense3=TimeDistributed(Dense(n_nodes,use_bias=1,\n",
    "               kernel_regularizer=regularizers.l1_l2(l1=lamda_reg,l2=lamda_reg)))(x)\n",
    "  activ_dense3=keras.layers.ELU(alpha=1.0)(dense3)\n",
    "  dropout3=Dropout(drop_frac)(dense3)\n",
    "  #dense4=Dense(n_nodes, activation='linear',use_bias=1,kernel_regularizer=regularizers.l1_l2(l1=0.05,l2=0.05))(dense3)\n",
    "  main_output=Dense(1, activation='linear',name='main_output')(dropout3)\n",
    "  \n",
    "  model=Model(inputs=[main_input],outputs=[main_output,rho_out])\n",
    "  return model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def createModel(\\n        input_shape1,\\n        input_shape2,\\n        lstm_nodes, \\n        lstm_bias, \\n        drop_frac, \\n        feedforward_nodes, \\n        lamda_reg, \\n        n_nodes):\\n  \\n  \\n  main_input=Input(shape=(input_shape1, input_shape2), name='main_input')\\n  #stm1=LSTM(lstm_nodes,return_sequences=True, use_bias=lstm_bias, recurrent_dropout=drop_frac)(main_input)\\n  #dense0=Dense(feedforward_nodes, activation='relu', use_bias=1,\\n  #             kernel_regularizer=regularizers.l1_l2(l1=lamda_reg,l2=lamda_reg))(main_input)\\n  #dropout0=Dropout(drop_frac)(dense0)\\n  mlstm_out=mLSTM(lstm_nodes,return_sequences=True, use_bias=lstm_bias, recurrent_dropout=drop_frac)(main_input)\\n  dense1=TimeDistributed(Dense(feedforward_nodes,use_bias=1,\\n               kernel_regularizer=regularizers.l1_l2(l1=lamda_reg,l2=lamda_reg)))(mlstm_out)\\n  activ_dense1=keras.layers.ELU(alpha=1.0)(dense1)\\n  #dropout1=Dropout(drop_frac)(activ_dense1)\\n  #dense2=Dense(feedforward_nodes, activation=keras.layers.ELU(alpha=1.0),use_bias=1,kernel_regularizer=regularizers.l1_l2(l1=0.05,l2=0.05))(dense1)\\n  rho_out=TimeDistributed(Dense(1, activation='linear'),name='aux_output')(activ_dense1)\\n  #auxiliary_input=Input(shape=(aux_train_X.shape[1],aux_train_X.shape[2]),name='aux_input')\\n  x=concatenate([rho_out,main_input])\\n  dense3=TimeDistributed(Dense(n_nodes,use_bias=1,\\n               kernel_regularizer=regularizers.l1_l2(l1=lamda_reg,l2=lamda_reg)))(x)\\n  activ_dense3=keras.layers.ELU(alpha=1.0)(dense3)\\n  #dropout2=Dropout(drop_frac)(dense3)\\n  #dense4=Dense(n_nodes, activation='linear',use_bias=1,kernel_regularizer=regularizers.l1_l2(l1=0.05,l2=0.05))(dense3)\\n  main_output=Dense(1, activation='linear',name='main_output')(activ_dense3)\\n  \\n  model=Model(inputs=[main_input],outputs=[main_output,rho_out])\\n  return model;\\n  \\n  \""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Temporary Save for Model\"\"\"\n",
    "\"\"\"def createModel(\n",
    "        input_shape1,\n",
    "        input_shape2,\n",
    "        lstm_nodes, \n",
    "        lstm_bias, \n",
    "        drop_frac, \n",
    "        feedforward_nodes, \n",
    "        lamda_reg, \n",
    "        n_nodes):\n",
    "  \n",
    "  \n",
    "  main_input=Input(shape=(input_shape1, input_shape2), name='main_input')\n",
    "  #stm1=LSTM(lstm_nodes,return_sequences=True, use_bias=lstm_bias, recurrent_dropout=drop_frac)(main_input)\n",
    "  #dense0=Dense(feedforward_nodes, activation='relu', use_bias=1,\n",
    "  #             kernel_regularizer=regularizers.l1_l2(l1=lamda_reg,l2=lamda_reg))(main_input)\n",
    "  #dropout0=Dropout(drop_frac)(dense0)\n",
    "  mlstm_out=mLSTM(lstm_nodes,return_sequences=True, use_bias=lstm_bias, recurrent_dropout=drop_frac)(main_input)\n",
    "  dense1=TimeDistributed(Dense(feedforward_nodes,use_bias=1,\n",
    "               kernel_regularizer=regularizers.l1_l2(l1=lamda_reg,l2=lamda_reg)))(mlstm_out)\n",
    "  activ_dense1=keras.layers.ELU(alpha=1.0)(dense1)\n",
    "  #dropout1=Dropout(drop_frac)(activ_dense1)\n",
    "  #dense2=Dense(feedforward_nodes, activation=keras.layers.ELU(alpha=1.0),use_bias=1,kernel_regularizer=regularizers.l1_l2(l1=0.05,l2=0.05))(dense1)\n",
    "  rho_out=TimeDistributed(Dense(1, activation='linear'),name='aux_output')(activ_dense1)\n",
    "  #auxiliary_input=Input(shape=(aux_train_X.shape[1],aux_train_X.shape[2]),name='aux_input')\n",
    "  x=concatenate([rho_out,main_input])\n",
    "  dense3=TimeDistributed(Dense(n_nodes,use_bias=1,\n",
    "               kernel_regularizer=regularizers.l1_l2(l1=lamda_reg,l2=lamda_reg)))(x)\n",
    "  activ_dense3=keras.layers.ELU(alpha=1.0)(dense3)\n",
    "  #dropout2=Dropout(drop_frac)(dense3)\n",
    "  #dense4=Dense(n_nodes, activation='linear',use_bias=1,kernel_regularizer=regularizers.l1_l2(l1=0.05,l2=0.05))(dense3)\n",
    "  main_output=Dense(1, activation='linear',name='main_output')(activ_dense3)\n",
    "  \n",
    "  model=Model(inputs=[main_input],outputs=[main_output,rho_out])\n",
    "  return model;\n",
    "  \n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-VKB-7EhMqPY"
   },
   "source": [
    "# Without Dropout Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KxgHSrC6Mu71"
   },
   "outputs": [],
   "source": [
    "def normal_prediction( model, test_X, test_y , pad_steps):\n",
    "  \n",
    "  test_pred=model.predict({'main_input':test_X})\n",
    "  test_pred=test_pred[0];\n",
    "  test_pred=test_pred[:,pad_steps:,:];\n",
    "  test_y=test_y[:,pad_steps:,:];\n",
    "  test_rmse=np.mean(np.sqrt(np.divide(np.sum(np.multiply(test_y[:,:,1],\n",
    "                                                          np.square(test_pred[:,:,0]-test_y[:,:,0])),axis=1),\n",
    "                                       np.sum(test_y[:,:,1],axis=1))))\n",
    "  params = [test_rmse, test_pred, test_y];\n",
    "  return params;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uViNjYAdQOI4"
   },
   "source": [
    "# Dropout Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HR4Ya3vtQRCq"
   },
   "outputs": [],
   "source": [
    "def dropout_prediction( model, n_iter, test_X, test_y , pad_steps):\n",
    "  \n",
    "  kdp = KerasDropoutPrediction(model);\n",
    "  test_pred = kdp.predict(test_X, n_iter=n_iter)\n",
    "  test_pred = test_pred[pad_steps:,:,:]\n",
    "  \n",
    "  test_pred_uq_mean = test_pred.mean(axis=-1).transpose()\n",
    "  test_pred_uq_std = test_pred.std(axis=-1).transpose()\n",
    "  test_rmse_dropout=np.mean(np.sqrt(np.divide(np.sum(np.multiply(test_y[:,:,1],\n",
    "                                                                 np.square(test_pred_uq_mean[:,:]-test_y[:,:,0])),axis=1),\n",
    "                                              np.sum(test_y[:,:,1],axis=1))));\n",
    "  params = [test_rmse_dropout, test_pred, test_y];\n",
    "  return params;\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NI7jXh-4pm1n"
   },
   "source": [
    "# Inconsitency without dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2xxpRBU2psRZ"
   },
   "outputs": [],
   "source": [
    "def normal_physical_inconsistency(tol, test_pred, depth_steps):\n",
    "  \n",
    "  test_density=actual_density(test_pred);\n",
    "  test_count=np.zeros(test_density.shape[0]);\n",
    "  for i in range(test_density.shape[0]):\n",
    "      for j in range(test_density.shape[1]-1):\n",
    "          if test_density[i,j]-test_density[i,j+1]>tol:\n",
    "              test_count[i]=test_count[i]+1;\n",
    "      test_count[i]=test_count[i]/depth_steps;\n",
    "\n",
    "  test_incon=np.sum(test_count)/test_density.shape[0];\n",
    "  return test_incon;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tt3DEITCsPpz"
   },
   "source": [
    "# Inconsistency of all MC samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVY1Y0dqsUm8"
   },
   "outputs": [],
   "source": [
    "def physical_inconsistency_all_sample(tol, test_pred_do, depth_steps):\n",
    "  \n",
    "  test_pred_do=np.swapaxes(test_pred_do,0,2);\n",
    "  density_test_pred_do=actual_density(test_pred_do);\n",
    "  \n",
    "  test_count_uq=np.zeros(test_pred_do.shape[0]);\n",
    "  for k in range(density_test_pred_do.shape[0]):\n",
    "      test_count=np.zeros(density_test_pred_do.shape[1])\n",
    "      for i in range(density_test_pred_do.shape[1]):\n",
    "          for j in range(density_test_pred_do.shape[2]-1):\n",
    "              if density_test_pred_do[k,i,j]-density_test_pred_do[k,i,j+1]>tol:\n",
    "                  test_count[i]=test_count[i]+1;\n",
    "          test_count[i]=test_count[i]/depth_steps;\n",
    "      test_count_uq[k]=np.sum(test_count)/density_test_pred_do.shape[1];\n",
    "  test_incon_uq=np.sum(test_count_uq)/density_test_pred_do.shape[0];\n",
    "\n",
    "\n",
    "  test_incon_uq=np.sum(test_count_uq)/density_test_pred_do.shape[0];\n",
    "  return test_incon_uq;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p-value computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p_values(test_pred_do, test_y1):\n",
    "    test_pred_do=np.swapaxes(test_pred_do,0,2);\n",
    "    p_values=np.zeros((test_pred_do.shape[1],test_pred_do.shape[2]));\n",
    "    sample_mean=np.mean(test_pred_do,axis=0);\n",
    "    print(test_pred_do.shape)\n",
    "    print(test_y1.shape)\n",
    "    for i in range(test_pred_do.shape[1]):\n",
    "        for j in range(test_pred_do.shape[2]):\n",
    "            diff=np.absolute(sample_mean[i,j]-test_y1[i,j,0])\n",
    "            count=0;\n",
    "            for k in range(test_pred_do.shape[0]):\n",
    "                if test_pred_do[k,i,j]>(sample_mean[i,j]+diff) or test_pred_do[k,i,j]<(sample_mean[i,j]-diff):\n",
    "                    count=count+1;\n",
    "            p_values[i,j]=count/test_pred_do.shape[0];\n",
    "    return p_values;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots of p-value vs residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_p_value_vs_residuals(test_p_values, test_pred_do, test_y1):\n",
    "    test_pred_do=np.swapaxes(test_pred_do,0,2);\n",
    "    sample_mean=np.mean(test_pred_do,axis=0);\n",
    "    print('sample mean shape',sample_mean.shape)\n",
    "    mask=test_y1[:,:,1].reshape((-1,));\n",
    "    ix=np.where(mask==1);\n",
    "    residuals=np.absolute(sample_mean-test_y1[:,:,0]).reshape((-1,));\n",
    "    test_p_values=test_p_values.reshape((-1,));\n",
    "    #pyplot.scatter(residuals[ix],test_p_values[ix]);\n",
    "    \n",
    "    #figure 1\n",
    "    pyplot.figure();\n",
    "    pyplot.hist2d(residuals[ix],test_p_values[ix],bins=[20,100], norm=LogNorm());\n",
    "    pyplot.xlabel('residuals');\n",
    "    pyplot.ylabel('p-values');\n",
    "    pyplot.colorbar();\n",
    "    pyplot.show();\n",
    "    \n",
    "    #figure 2\n",
    "    n_bins=20;\n",
    "    pyplot.figure();\n",
    "    pyplot.hist(test_p_values[ix],bins=n_bins);\n",
    "    pyplot.xlabel('p-values');\n",
    "    pyplot.show();\n",
    "    \n",
    "    #figure 3\n",
    "    pyplot.figure();\n",
    "    pyplot.hist(residuals[ix],bins=50);\n",
    "    pyplot.xlabel('Residuals');\n",
    "    pyplot.show();\n",
    "    print(\"Mean P-value = \"+str(np.mean(test_p_values[ix])));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gjl0oQGbZnt_"
   },
   "source": [
    "# Physics Guided Architecture LSTM class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTInEw64a8CG"
   },
   "outputs": [],
   "source": [
    "def PGA_LSTM_train_test(\n",
    "      iteration,\n",
    "      usePad,\n",
    "      tr_frac,\n",
    "      val_frac,\n",
    "      patience_val,\n",
    "      num_epochs,\n",
    "      batch_size,\n",
    "      lstm_nodes,\n",
    "      feedforward_nodes,\n",
    "      mask_value, \n",
    "      drop_frac,\n",
    "      lstm_bias,\n",
    "      n_nodes,\n",
    "      use_GLM,\n",
    "      use_temporal_feature,\n",
    "      lamda_reg ):\n",
    "  \n",
    "  \n",
    "    #Start of function\n",
    "    pad_steps = 10;\n",
    "    \n",
    "    #read Data\n",
    "    [train_X,train_y_temperature,train_y_glm,test_X,test_y_temperature,test_y_glm]=read_Data();\n",
    "    \n",
    "    #Add GLM feature\n",
    "    if use_GLM==1:\n",
    "        train_X=np.dstack((train_X,train_y_glm));\n",
    "        test_X=np.dstack((test_X,test_y_glm));\n",
    "    \n",
    "    depth_steps=train_X.shape[1];\n",
    "    \n",
    "    #Normalise Data\n",
    "    train_X=transform_3d_to_2d(train_X);\n",
    "    test_X=transform_3d_to_2d(test_X);\n",
    "    \n",
    "    m1_train_mean = train_X.mean(axis=0);\n",
    "    m1_train_std = train_X.std(axis=0);\n",
    "    train_X = (train_X - m1_train_mean) / m1_train_std;\n",
    "    test_X = (test_X - m1_train_mean) / m1_train_std;\n",
    "    \n",
    "    train_X=transform_2d_to_3d(train_X,depth_steps);\n",
    "    test_X=transform_2d_to_3d(test_X,depth_steps);\n",
    "    \n",
    "    #Create train subset\n",
    "    [ix,train_X,train_y_temperature,train_y_glm]=train_subset(train_X,train_y_temperature, train_y_glm);\n",
    "    \n",
    "    #creating path and filename for storage of results\n",
    "    exp_name = 'pga_lstm_model_' + str(num_epochs)  + '_dropout_frac_' + str(drop_frac) + '_feedforward_nodes' + str(feedforward_nodes) + '_lstm_nodes' + str(\n",
    "        lstm_nodes) + '_val_frac' + str(val_frac) + '_trfrac' + str(tr_frac) + '_iter' + str(iteration)+'_n_nodes'+str(n_nodes)+'_use_GLM'+str(use_GLM)+'_use_temporal_features'+str(use_temporal_feature) + '_lamda_reg'+str(lamda_reg)\n",
    "    exp_name = exp_name.replace('.', 'pt')\n",
    "    #results_dir = '/home/karpatne/Documents/Lake Temperature Modelling/Results/paa_lstm_glm_linear/'\n",
    "    results_dir='C:\\\\Users\\\\arkad\\\\Documents\\\\Lake Temperature Modelling\\\\Results\\\\test\\\\'\n",
    "    model_name = results_dir + exp_name + '_model.h5'  # storing the trained model\n",
    "    results_name = results_dir + exp_name + '_results.mat'  # storing the results of the model\n",
    "    \n",
    "    train_y_temperature=transform_3d_to_2d(train_y_temperature);\n",
    "    test_y_temperature=transform_3d_to_2d(test_y_temperature);\n",
    "    \n",
    "    #Create Density labels \n",
    "    train_y_density=np.zeros(np.shape(train_y_temperature));\n",
    "    test_y_density=np.zeros(np.shape(test_y_temperature));\n",
    "    train_y_density[:,1], test_y_density[:,1] = train_y_temperature[:,1], test_y_temperature[:,1]\n",
    "    train_y_density[:,0], test_y_density[:,0] = density(train_y_temperature[:,0]), density(test_y_temperature[:,0])\n",
    "    \n",
    "    # density output normalisation\n",
    "    mean = np.nanmean(train_y_density[:, 0]);\n",
    "    std = np.nanstd(train_y_density[:, 0]);\n",
    "    train_y_density[:, 0] = (train_y_density[:, 0] - mean) / std;\n",
    "    test_y_density[:, 0] = (test_y_density[:, 0] - mean) / std;\n",
    "    \n",
    "    #masking output labels\n",
    "    [train__y_density,train_y_temperature]=masking_output_labels(train_y_density,train_y_temperature,mask_value);\n",
    "    [test__y_density,test_y_temperature]=masking_output_labels(test_y_density,test_y_temperature,mask_value);\n",
    "    \n",
    "    #reshaping train/test output density/temperature labels\n",
    "    train_y_density=transform_2d_to_3d(train_y_density,depth_steps); \n",
    "    train_y_temperature=transform_2d_to_3d(train_y_temperature,depth_steps); \n",
    "    test_y_density=transform_2d_to_3d(test_y_density,depth_steps); \n",
    "    test_y_temperature=transform_2d_to_3d(test_y_temperature,depth_steps); \n",
    "    \n",
    "    #perform edge padding\n",
    "    [train_X_pad,train_y_density_pad,train_y_temperature_pad]=edge_padding(train_X,train_y_density,train_y_temperature,pad_steps);\n",
    "    [test_X_pad,test_y_density_pad,test_y_temperature_pad]=edge_padding(test_X,test_y_density,test_y_temperature,pad_steps);\n",
    "    \n",
    "    #create auxiliary dataset (same as input data)\n",
    "    aux_train_X=train_X_pad;\n",
    "    aux_test_X=test_X_pad;\n",
    "    \n",
    "    model=createModel(\n",
    "        train_X_pad.shape[1],\n",
    "        train_X_pad.shape[2],\n",
    "        lstm_nodes, \n",
    "        lstm_bias, \n",
    "        drop_frac, \n",
    "        feedforward_nodes, \n",
    "        lamda_reg, \n",
    "        n_nodes);\n",
    "    \n",
    "    model.summary();\n",
    "    \n",
    "    optimiser = optimizers.Adadelta(clipnorm=3)\n",
    "    #optimiser = optimizers.Adam(clipnorm=3)\n",
    "    \n",
    "    model.compile(\n",
    "        loss={'main_output': masked_mean_squared_error, 'aux_output': masked_mean_squared_error}, \n",
    "        optimizer=optimiser,\n",
    "        loss_weights={'main_output':1.,'aux_output':0.2})\n",
    "    \n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "                            monitor='val_main_output_loss', \n",
    "                            patience=patience_val, \n",
    "                            verbose=1)\n",
    "    history=model.fit(\n",
    "                {'main_input':train_X_pad},\n",
    "                {'main_output':train_y_temperature_pad,'aux_output':train_y_density_pad},\n",
    "                epochs=num_epochs, \n",
    "                batch_size=batch_size, \n",
    "                verbose=2, \n",
    "                shuffle=False,\n",
    "                validation_split=val_frac, \n",
    "                callbacks=[early_stopping, TerminateOnNaN()]);\n",
    "    \n",
    "    #Calculating model RMSE \n",
    "    [test_rmse1, test_pred1, test_y1] = normal_prediction(model, test_X_pad, test_y_temperature_pad, pad_steps);\n",
    "    [train_rmse1, train_pred1, train_y1] = normal_prediction(model, train_X_pad, train_y_temperature_pad, pad_steps);\n",
    "    \n",
    "    print('Without dropout = TrainRMSE : ' +str(train_rmse1) + ' TestRMSE : '+str(test_rmse1));\n",
    "    \n",
    "    [test_rmse_dropout, test_pred_do, test_y1] = dropout_prediction(model,100,test_X_pad, test_y_temperature_pad[:,pad_steps:,:], pad_steps);\n",
    "    [train_rmse_dropout, train_pred_do, train_y1] = dropout_prediction(model,100,train_X_pad, train_y_temperature_pad[:,pad_steps:,:], pad_steps);\n",
    "    \n",
    "    print('With dropout = TrainRMSE : ' +str(train_rmse_dropout) + ' TestRMSE : '+str(test_rmse_dropout));\n",
    "    \n",
    "    \n",
    "    #Calculating Physical Inconsistencies\n",
    "    tol=0.0001;\n",
    "    test_inconsistency_without_dropout=normal_physical_inconsistency(tol, test_pred1, depth_steps);\n",
    "    train_inconsistency_without_dropout=normal_physical_inconsistency(tol, train_pred1, depth_steps);\n",
    "    \n",
    "    print(\"Without dropout : Test Incon = \"+str(test_inconsistency_without_dropout)+'  Train Incon = '+str(train_inconsistency_without_dropout))\n",
    "    \n",
    "    test_pred_uq_mean = test_pred_do.mean(axis=-1).transpose();\n",
    "    train_pred_uq_mean = train_pred_do.mean(axis=-1).transpose();\n",
    "    test_inconsistency_dropout_mean=normal_physical_inconsistency(tol, test_pred_uq_mean, depth_steps);\n",
    "    train_inconsistency_dropout_mean=normal_physical_inconsistency(tol, train_pred_uq_mean, depth_steps);\n",
    "    \n",
    "    print(\"With dropout Inconsistency of sample mean: Test Incon = \"+str(test_inconsistency_dropout_mean)+'  Train Incon = '+str(train_inconsistency_dropout_mean))\n",
    "    \n",
    "    test_inconsistency_dropout_all=physical_inconsistency_all_sample(tol, test_pred_do, depth_steps);\n",
    "    train_inconsistency_dropout_all=physical_inconsistency_all_sample(tol, train_pred_do, depth_steps);\n",
    "    \n",
    "    print(\"With dropout Inconsistency of all samples: Test Incon = \"+str(test_inconsistency_dropout_all)+'  Train Incon = '+str(train_inconsistency_dropout_all))\n",
    "    \n",
    "    test_p_values=compute_p_values(test_pred_do, test_y1);\n",
    "    train_p_values=compute_p_values(train_pred_do, train_y1);\n",
    "    print('Train p-values : '+str(np.nanmean(train_p_values)));\n",
    "    print('Test p-values : '+str(np.nanmean(test_p_values)));\n",
    "    plot_p_value_vs_residuals(test_p_values, test_pred_do, test_y1);\n",
    "    \n",
    "    #model.save(model_name)\n",
    "    spio.savemat(results_name,{'test_pred_temperature':test_pred1,\n",
    "                               'test_y_temperature':test_y1,\n",
    "                               'train_pred_temperature':train_pred1, \n",
    "                               'train_y_temperature':train_y1,\n",
    "                               'train_rmse':train_rmse1,\n",
    "                               'test_rmse':test_rmse1,\n",
    "                               'train_rmse_dropout':train_rmse_dropout,\n",
    "                               'test_rmse_dropout':test_rmse_dropout,\n",
    "                               'test_incon_without_dropout':test_inconsistency_without_dropout,\n",
    "                               'train_inconsistency_without_dropout':train_inconsistency_without_dropout,\n",
    "                               'test_inconsistency_dropout_mean':test_inconsistency_dropout_mean,\n",
    "                               'train_inconsistency_dropout_mean':train_inconsistency_dropout_mean,\n",
    "                               'test_inconsistency_dropout_all':test_inconsistency_dropout_all,\n",
    "                               'train_inconsistency_dropout_all':train_inconsistency_dropout_all,\n",
    "                               'test_predictions_all':test_pred_do,\n",
    "                               'train_predictions_all':train_pred_do,\n",
    "                               'train_index':ix,\n",
    "                               'train_main_loss':history.history['main_output_loss'],\n",
    "                               'train_aux_output_loss':history.history['aux_output_loss'],\n",
    "                               'train_loss':history.history['loss'], \n",
    "                               'train_val_loss':history.history['val_loss']})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhZlBlBMbW_k"
   },
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 194452,
     "status": "error",
     "timestamp": 1568315598561,
     "user": {
      "displayName": "Arka Daw",
      "photoUrl": "",
      "userId": "06797637409844358433"
     },
     "user_tz": 240
    },
    "id": "s6KplrELba0F",
    "outputId": "b6afa8b4-3b24-4fc5-80f2-1af17e3c6781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 60, 17)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "m_lstm_1 (mLSTM)                (None, 60, 8)        832         main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 60, 5)        45          m_lstm_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "elu_1 (ELU)                     (None, 60, 5)        0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 60, 5)        0           elu_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (TimeDistributed)    (None, 60, 1)        6           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 60, 18)       0           aux_output[0][0]                 \n",
      "                                                                 main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 60, 5)        95          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 60, 5)        0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 60, 1)        6           dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 984\n",
      "Trainable params: 984\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 351 samples, validate on 40 samples\n",
      "Epoch 1/500\n",
      " - 2s - loss: 273761662687.5022 - main_output_loss: 7324131256.3297 - aux_output_loss: 1332187645065.2024 - val_loss: 143.5233 - val_main_output_loss: 116.4619 - val_aux_output_loss: 121.7668\n",
      "Epoch 2/500\n",
      " - 1s - loss: 1111605.0778 - main_output_loss: 183316.0356 - aux_output_loss: 4641431.4485 - val_loss: 128.0004 - val_main_output_loss: 115.6959 - val_aux_output_loss: 48.0016\n",
      "Epoch 3/500\n",
      " - 0s - loss: 2401313213.1326 - main_output_loss: 1026031093.4082 - aux_output_loss: 6876411286.1266 - val_loss: 124.9132 - val_main_output_loss: 115.3700 - val_aux_output_loss: 34.2143\n",
      "Epoch 4/500\n",
      " - 0s - loss: 424057.3109 - main_output_loss: 111146.8875 - aux_output_loss: 1564538.6605 - val_loss: 119.7105 - val_main_output_loss: 114.3209 - val_aux_output_loss: 13.4814\n",
      "Epoch 5/500\n",
      " - 0s - loss: 434639302.0206 - main_output_loss: 38578803.2855 - aux_output_loss: 1980302378.8780 - val_loss: 118.6224 - val_main_output_loss: 114.2881 - val_aux_output_loss: 8.2412\n",
      "Epoch 6/500\n",
      " - 0s - loss: 2400.9757 - main_output_loss: 479.5305 - aux_output_loss: 9593.8122 - val_loss: 117.1306 - val_main_output_loss: 113.4761 - val_aux_output_loss: 4.9031\n",
      "Epoch 7/500\n",
      " - 0s - loss: 49790.7895 - main_output_loss: 14849.9963 - aux_output_loss: 174690.5985 - val_loss: 118.1053 - val_main_output_loss: 114.5592 - val_aux_output_loss: 4.3867\n",
      "Epoch 8/500\n",
      " - 0s - loss: 465.4208 - main_output_loss: 236.5277 - aux_output_loss: 1131.1384 - val_loss: 120.1880 - val_main_output_loss: 116.6109 - val_aux_output_loss: 4.5755\n",
      "Epoch 9/500\n",
      " - 0s - loss: 2732.2573 - main_output_loss: 520.4880 - aux_output_loss: 11045.5591 - val_loss: 120.2244 - val_main_output_loss: 116.7427 - val_aux_output_loss: 4.1587\n",
      "Epoch 10/500\n",
      " - 0s - loss: 812.3418 - main_output_loss: 286.6110 - aux_output_loss: 2615.4269 - val_loss: 119.4566 - val_main_output_loss: 116.2572 - val_aux_output_loss: 2.8131\n",
      "Epoch 11/500\n",
      " - 0s - loss: 15758.4050 - main_output_loss: 2724.7206 - aux_output_loss: 65155.2545 - val_loss: 120.7235 - val_main_output_loss: 117.6865 - val_aux_output_loss: 2.0478\n",
      "Epoch 12/500\n",
      " - 0s - loss: 175.6661 - main_output_loss: 158.6659 - aux_output_loss: 71.8828 - val_loss: 119.8999 - val_main_output_loss: 116.7946 - val_aux_output_loss: 2.4591\n",
      "Epoch 13/500\n",
      " - 0s - loss: 15054.5289 - main_output_loss: 2686.9119 - aux_output_loss: 61825.0231 - val_loss: 121.5237 - val_main_output_loss: 118.4125 - val_aux_output_loss: 2.5081\n",
      "Epoch 14/500\n",
      " - 0s - loss: 170.2948 - main_output_loss: 147.2633 - aux_output_loss: 102.1315 - val_loss: 121.4703 - val_main_output_loss: 118.4483 - val_aux_output_loss: 2.0980\n",
      "Epoch 15/500\n",
      " - 0s - loss: 149.6422 - main_output_loss: 138.9733 - aux_output_loss: 40.3286 - val_loss: 119.8025 - val_main_output_loss: 116.7279 - val_aux_output_loss: 2.3514\n",
      "Epoch 16/500\n",
      " - 0s - loss: 108872.5732 - main_output_loss: 74612.4131 - aux_output_loss: 171287.7687 - val_loss: 118.2236 - val_main_output_loss: 115.0419 - val_aux_output_loss: 2.8513\n",
      "Epoch 17/500\n",
      " - 0s - loss: 137.5982 - main_output_loss: 127.7272 - aux_output_loss: 36.2757 - val_loss: 113.6289 - val_main_output_loss: 110.3350 - val_aux_output_loss: 3.3599\n",
      "Epoch 18/500\n",
      " - 0s - loss: 171.3567 - main_output_loss: 152.8868 - aux_output_loss: 79.1962 - val_loss: 108.5479 - val_main_output_loss: 105.0210 - val_aux_output_loss: 4.4215\n",
      "Epoch 19/500\n",
      " - 0s - loss: 580.2827 - main_output_loss: 440.9070 - aux_output_loss: 683.6427 - val_loss: 100.0274 - val_main_output_loss: 96.2701 - val_aux_output_loss: 5.5065\n",
      "Epoch 20/500\n",
      " - 0s - loss: 2255.4448 - main_output_loss: 1947.5334 - aux_output_loss: 1526.2463 - val_loss: 91.3937 - val_main_output_loss: 87.2597 - val_aux_output_loss: 7.3133\n",
      "Epoch 21/500\n",
      " - 0s - loss: 129.2648 - main_output_loss: 116.6419 - aux_output_loss: 49.7270 - val_loss: 87.4041 - val_main_output_loss: 83.4195 - val_aux_output_loss: 6.4925\n",
      "Epoch 22/500\n",
      " - 0s - loss: 112.3602 - main_output_loss: 104.2077 - aux_output_loss: 27.2880 - val_loss: 74.3935 - val_main_output_loss: 69.9434 - val_aux_output_loss: 8.7007\n",
      "Epoch 23/500\n",
      " - 0s - loss: 1073772.0124 - main_output_loss: 1003487.5016 - aux_output_loss: 351409.0731 - val_loss: 69.7276 - val_main_output_loss: 65.2567 - val_aux_output_loss: 8.7442\n",
      "Epoch 24/500\n",
      " - 0s - loss: 71.7020 - main_output_loss: 66.0480 - aux_output_loss: 14.6269 - val_loss: 58.4753 - val_main_output_loss: 53.6220 - val_aux_output_loss: 10.5522\n",
      "Epoch 25/500\n",
      " - 0s - loss: 159.7574 - main_output_loss: 148.9648 - aux_output_loss: 40.2238 - val_loss: 51.4746 - val_main_output_loss: 46.5500 - val_aux_output_loss: 10.8511\n",
      "Epoch 26/500\n",
      " - 0s - loss: 1942.9669 - main_output_loss: 1805.6203 - aux_output_loss: 672.9295 - val_loss: 45.4255 - val_main_output_loss: 40.4222 - val_aux_output_loss: 11.1646\n",
      "Epoch 27/500\n",
      " - 0s - loss: 57.9985 - main_output_loss: 52.4361 - aux_output_loss: 13.9466 - val_loss: 37.1788 - val_main_output_loss: 32.0508 - val_aux_output_loss: 11.7455\n",
      "Epoch 28/500\n",
      " - 0s - loss: 62.7415 - main_output_loss: 56.8534 - aux_output_loss: 15.5522 - val_loss: 32.3277 - val_main_output_loss: 27.2027 - val_aux_output_loss: 11.7292\n",
      "Epoch 29/500\n",
      " - 0s - loss: 1872.9783 - main_output_loss: 1760.2257 - aux_output_loss: 549.8733 - val_loss: 28.7428 - val_main_output_loss: 23.6113 - val_aux_output_loss: 11.7721\n",
      "Epoch 30/500\n",
      " - 0s - loss: 66.6714 - main_output_loss: 61.2164 - aux_output_loss: 13.4211 - val_loss: 24.5151 - val_main_output_loss: 19.3587 - val_aux_output_loss: 11.9445\n",
      "Epoch 31/500\n",
      " - 0s - loss: 39.6962 - main_output_loss: 35.0814 - aux_output_loss: 9.2691 - val_loss: 21.9136 - val_main_output_loss: 16.7932 - val_aux_output_loss: 11.8233\n",
      "Epoch 32/500\n",
      " - 0s - loss: 40.0825 - main_output_loss: 35.4385 - aux_output_loss: 9.4852 - val_loss: 19.1712 - val_main_output_loss: 14.0826 - val_aux_output_loss: 11.7663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/500\n",
      " - 0s - loss: 38.7422 - main_output_loss: 34.1409 - aux_output_loss: 9.4002 - val_loss: 17.6171 - val_main_output_loss: 12.5958 - val_aux_output_loss: 11.5484\n",
      "Epoch 34/500\n",
      " - 0s - loss: 38.5324 - main_output_loss: 34.1132 - aux_output_loss: 8.5998 - val_loss: 16.2959 - val_main_output_loss: 11.3597 - val_aux_output_loss: 11.2605\n",
      "Epoch 35/500\n",
      " - 0s - loss: 29.9225 - main_output_loss: 25.7026 - aux_output_loss: 7.7496 - val_loss: 14.9109 - val_main_output_loss: 10.0714 - val_aux_output_loss: 10.9200\n",
      "Epoch 36/500\n",
      " - 0s - loss: 30.6332 - main_output_loss: 26.5696 - aux_output_loss: 7.1010 - val_loss: 13.0112 - val_main_output_loss: 8.2086 - val_aux_output_loss: 10.8597\n",
      "Epoch 37/500\n",
      " - 0s - loss: 217.4417 - main_output_loss: 209.4016 - aux_output_loss: 27.1224 - val_loss: 12.8666 - val_main_output_loss: 8.2154 - val_aux_output_loss: 10.2705\n",
      "Epoch 38/500\n",
      " - 0s - loss: 26.7287 - main_output_loss: 22.8816 - aux_output_loss: 6.3444 - val_loss: 12.8428 - val_main_output_loss: 8.3468 - val_aux_output_loss: 9.6679\n",
      "Epoch 39/500\n",
      " - 0s - loss: 25.7066 - main_output_loss: 22.0458 - aux_output_loss: 5.5774 - val_loss: 11.4475 - val_main_output_loss: 7.0002 - val_aux_output_loss: 9.5835\n",
      "Epoch 40/500\n",
      " - 0s - loss: 45.5676 - main_output_loss: 41.4956 - aux_output_loss: 7.7784 - val_loss: 10.6774 - val_main_output_loss: 6.2899 - val_aux_output_loss: 9.4328\n",
      "Epoch 41/500\n",
      " - 0s - loss: 27.6116 - main_output_loss: 24.0366 - aux_output_loss: 5.4540 - val_loss: 10.3335 - val_main_output_loss: 6.0626 - val_aux_output_loss: 9.0341\n",
      "Epoch 42/500\n",
      " - 0s - loss: 25.7385 - main_output_loss: 22.2478 - aux_output_loss: 5.2508 - val_loss: 10.5258 - val_main_output_loss: 6.4246 - val_aux_output_loss: 8.4097\n",
      "Epoch 43/500\n",
      " - 0s - loss: 23.4933 - main_output_loss: 20.0820 - aux_output_loss: 5.0443 - val_loss: 9.6409 - val_main_output_loss: 5.5689 - val_aux_output_loss: 8.4316\n",
      "Epoch 44/500\n",
      " - 0s - loss: 158.8568 - main_output_loss: 151.0097 - aux_output_loss: 27.4054 - val_loss: 9.4924 - val_main_output_loss: 5.5187 - val_aux_output_loss: 8.1421\n",
      "Epoch 45/500\n",
      " - 0s - loss: 21.7582 - main_output_loss: 18.5189 - aux_output_loss: 4.5797 - val_loss: 8.9260 - val_main_output_loss: 5.0318 - val_aux_output_loss: 7.9687\n",
      "Epoch 46/500\n",
      " - 0s - loss: 33.2413 - main_output_loss: 29.8713 - aux_output_loss: 5.4584 - val_loss: 8.8240 - val_main_output_loss: 5.0552 - val_aux_output_loss: 7.5567\n",
      "Epoch 47/500\n",
      " - 0s - loss: 21.4841 - main_output_loss: 18.4036 - aux_output_loss: 4.2489 - val_loss: 8.9118 - val_main_output_loss: 5.2835 - val_aux_output_loss: 7.1028\n",
      "Epoch 48/500\n",
      " - 0s - loss: 64.1761 - main_output_loss: 59.7849 - aux_output_loss: 11.0004 - val_loss: 8.5461 - val_main_output_loss: 4.9891 - val_aux_output_loss: 6.9212\n",
      "Epoch 49/500\n",
      " - 0s - loss: 20.6993 - main_output_loss: 17.7412 - aux_output_loss: 4.0435 - val_loss: 8.3943 - val_main_output_loss: 4.9248 - val_aux_output_loss: 6.7081\n",
      "Epoch 50/500\n",
      " - 0s - loss: 20.1220 - main_output_loss: 17.2358 - aux_output_loss: 3.9039 - val_loss: 8.3089 - val_main_output_loss: 4.9352 - val_aux_output_loss: 6.4375\n",
      "Epoch 51/500\n",
      " - 0s - loss: 20.1953 - main_output_loss: 17.3988 - aux_output_loss: 3.6732 - val_loss: 8.0536 - val_main_output_loss: 4.7712 - val_aux_output_loss: 6.1984\n",
      "Epoch 52/500\n",
      " - 0s - loss: 20.1121 - main_output_loss: 17.3690 - aux_output_loss: 3.5911 - val_loss: 8.0553 - val_main_output_loss: 4.8471 - val_aux_output_loss: 6.0150\n",
      "Epoch 53/500\n",
      " - 0s - loss: 19.5324 - main_output_loss: 16.8369 - aux_output_loss: 3.5490 - val_loss: 7.9681 - val_main_output_loss: 4.8337 - val_aux_output_loss: 5.8241\n",
      "Epoch 54/500\n",
      " - 0s - loss: 19.5320 - main_output_loss: 16.9037 - aux_output_loss: 3.3851 - val_loss: 7.8205 - val_main_output_loss: 4.7456 - val_aux_output_loss: 5.6976\n",
      "Epoch 55/500\n",
      " - 0s - loss: 20.3781 - main_output_loss: 17.7960 - aux_output_loss: 3.3208 - val_loss: 7.4848 - val_main_output_loss: 4.4500 - val_aux_output_loss: 5.6548\n",
      "Epoch 56/500\n",
      " - 0s - loss: 19.2112 - main_output_loss: 16.6732 - aux_output_loss: 3.2766 - val_loss: 7.2720 - val_main_output_loss: 4.2916 - val_aux_output_loss: 5.5826\n",
      "Epoch 57/500\n",
      " - 0s - loss: 18.8284 - main_output_loss: 16.3484 - aux_output_loss: 3.1907 - val_loss: 7.3804 - val_main_output_loss: 4.4817 - val_aux_output_loss: 5.3653\n",
      "Epoch 58/500\n",
      " - 0s - loss: 18.8852 - main_output_loss: 16.4593 - aux_output_loss: 3.1055 - val_loss: 7.3516 - val_main_output_loss: 4.5170 - val_aux_output_loss: 5.2196\n",
      "Epoch 59/500\n",
      " - 0s - loss: 18.6205 - main_output_loss: 16.2349 - aux_output_loss: 3.0513 - val_loss: 7.0161 - val_main_output_loss: 4.2009 - val_aux_output_loss: 5.2680\n",
      "Epoch 60/500\n",
      " - 0s - loss: 18.8658 - main_output_loss: 16.4768 - aux_output_loss: 3.2233 - val_loss: 6.8563 - val_main_output_loss: 4.0847 - val_aux_output_loss: 5.1993\n",
      "Epoch 61/500\n",
      " - 0s - loss: 19.3370 - main_output_loss: 16.9998 - aux_output_loss: 3.1034 - val_loss: 6.7231 - val_main_output_loss: 3.9980 - val_aux_output_loss: 5.1095\n",
      "Epoch 62/500\n",
      " - 0s - loss: 18.1028 - main_output_loss: 15.8163 - aux_output_loss: 2.9799 - val_loss: 6.7199 - val_main_output_loss: 4.0361 - val_aux_output_loss: 5.0378\n",
      "Epoch 63/500\n",
      " - 0s - loss: 18.3235 - main_output_loss: 16.0837 - aux_output_loss: 2.8901 - val_loss: 6.4705 - val_main_output_loss: 3.8018 - val_aux_output_loss: 5.0895\n",
      "Epoch 64/500\n",
      " - 0s - loss: 17.8043 - main_output_loss: 15.5963 - aux_output_loss: 2.8773 - val_loss: 6.3157 - val_main_output_loss: 3.6955 - val_aux_output_loss: 4.9985\n",
      "Epoch 65/500\n",
      " - 0s - loss: 17.6021 - main_output_loss: 15.4396 - aux_output_loss: 2.7912 - val_loss: 6.4277 - val_main_output_loss: 3.8730 - val_aux_output_loss: 4.8082\n",
      "Epoch 66/500\n",
      " - 0s - loss: 26.7909 - main_output_loss: 24.4030 - aux_output_loss: 4.0340 - val_loss: 6.2612 - val_main_output_loss: 3.7193 - val_aux_output_loss: 4.8564\n",
      "Epoch 67/500\n",
      " - 0s - loss: 17.2410 - main_output_loss: 15.1305 - aux_output_loss: 2.7815 - val_loss: 6.1655 - val_main_output_loss: 3.6767 - val_aux_output_loss: 4.7234\n",
      "Epoch 68/500\n",
      " - 0s - loss: 17.1810 - main_output_loss: 15.1154 - aux_output_loss: 2.7006 - val_loss: 6.1007 - val_main_output_loss: 3.6642 - val_aux_output_loss: 4.6070\n",
      "Epoch 69/500\n",
      " - 0s - loss: 17.1221 - main_output_loss: 15.0827 - aux_output_loss: 2.6997 - val_loss: 6.0630 - val_main_output_loss: 3.6801 - val_aux_output_loss: 4.4789\n",
      "Epoch 70/500\n",
      " - 0s - loss: 17.5355 - main_output_loss: 15.5485 - aux_output_loss: 2.5799 - val_loss: 5.8399 - val_main_output_loss: 3.4799 - val_aux_output_loss: 4.5029\n",
      "Epoch 71/500\n",
      " - 0s - loss: 16.6501 - main_output_loss: 14.6934 - aux_output_loss: 2.5688 - val_loss: 5.7691 - val_main_output_loss: 3.4389 - val_aux_output_loss: 4.4829\n",
      "Epoch 72/500\n",
      " - 0s - loss: 16.9479 - main_output_loss: 15.0031 - aux_output_loss: 2.6242 - val_loss: 5.7690 - val_main_output_loss: 3.4885 - val_aux_output_loss: 4.3403\n",
      "Epoch 73/500\n",
      " - 0s - loss: 20.4479 - main_output_loss: 18.5408 - aux_output_loss: 2.5453 - val_loss: 5.8690 - val_main_output_loss: 3.6347 - val_aux_output_loss: 4.2384\n",
      "Epoch 74/500\n",
      " - 0s - loss: 18.9893 - main_output_loss: 17.1192 - aux_output_loss: 2.4832 - val_loss: 5.4261 - val_main_output_loss: 3.1768 - val_aux_output_loss: 4.4174\n",
      "Epoch 75/500\n",
      " - 0s - loss: 16.2626 - main_output_loss: 14.3954 - aux_output_loss: 2.5605 - val_loss: 5.3057 - val_main_output_loss: 3.0796 - val_aux_output_loss: 4.3877\n",
      "Epoch 76/500\n",
      " - 0s - loss: 16.1485 - main_output_loss: 14.3245 - aux_output_loss: 2.4575 - val_loss: 5.5520 - val_main_output_loss: 3.3945 - val_aux_output_loss: 4.1696\n",
      "Epoch 77/500\n",
      " - 0s - loss: 18.2994 - main_output_loss: 16.4978 - aux_output_loss: 2.4505 - val_loss: 5.4790 - val_main_output_loss: 3.3492 - val_aux_output_loss: 4.1329\n",
      "Epoch 78/500\n",
      " - 0s - loss: 16.1348 - main_output_loss: 14.3752 - aux_output_loss: 2.3389 - val_loss: 5.3493 - val_main_output_loss: 3.2494 - val_aux_output_loss: 4.0763\n",
      "Epoch 79/500\n",
      " - 0s - loss: 16.2975 - main_output_loss: 14.5551 - aux_output_loss: 2.3604 - val_loss: 5.4375 - val_main_output_loss: 3.3811 - val_aux_output_loss: 3.9757\n",
      "Epoch 80/500\n",
      " - 0s - loss: 15.9025 - main_output_loss: 14.1987 - aux_output_loss: 2.2735 - val_loss: 5.1242 - val_main_output_loss: 3.0701 - val_aux_output_loss: 4.0484\n",
      "Epoch 81/500\n",
      " - 0s - loss: 16.2093 - main_output_loss: 14.5247 - aux_output_loss: 2.2664 - val_loss: 5.2479 - val_main_output_loss: 3.2379 - val_aux_output_loss: 3.9157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      " - 0s - loss: 15.5322 - main_output_loss: 13.8794 - aux_output_loss: 2.2046 - val_loss: 5.1453 - val_main_output_loss: 3.1562 - val_aux_output_loss: 3.9310\n",
      "Epoch 83/500\n",
      " - 0s - loss: 15.6523 - main_output_loss: 14.0105 - aux_output_loss: 2.2366 - val_loss: 5.2745 - val_main_output_loss: 3.3191 - val_aux_output_loss: 3.8456\n",
      "Epoch 84/500\n",
      " - 0s - loss: 15.1749 - main_output_loss: 13.5588 - aux_output_loss: 2.2186 - val_loss: 5.1935 - val_main_output_loss: 3.2702 - val_aux_output_loss: 3.7884\n",
      "Epoch 85/500\n",
      " - 0s - loss: 15.4428 - main_output_loss: 13.8421 - aux_output_loss: 2.2116 - val_loss: 5.2469 - val_main_output_loss: 3.3583 - val_aux_output_loss: 3.6747\n",
      "Epoch 86/500\n",
      " - 0s - loss: 15.6926 - main_output_loss: 14.0936 - aux_output_loss: 2.2652 - val_loss: 4.8895 - val_main_output_loss: 3.0038 - val_aux_output_loss: 3.7200\n",
      "Epoch 87/500\n",
      " - 0s - loss: 19.0923 - main_output_loss: 17.4163 - aux_output_loss: 2.7174 - val_loss: 4.9265 - val_main_output_loss: 3.0654 - val_aux_output_loss: 3.6591\n",
      "Epoch 88/500\n",
      " - 0s - loss: 14.8915 - main_output_loss: 13.3423 - aux_output_loss: 2.1591 - val_loss: 4.9154 - val_main_output_loss: 3.0840 - val_aux_output_loss: 3.5970\n",
      "Epoch 89/500\n",
      " - 0s - loss: 15.0615 - main_output_loss: 13.5386 - aux_output_loss: 2.1047 - val_loss: 4.6844 - val_main_output_loss: 2.8510 - val_aux_output_loss: 3.6707\n",
      "Epoch 90/500\n",
      " - 0s - loss: 14.8238 - main_output_loss: 13.3167 - aux_output_loss: 2.0795 - val_loss: 4.8712 - val_main_output_loss: 3.0738 - val_aux_output_loss: 3.5496\n",
      "Epoch 91/500\n",
      " - 0s - loss: 14.8953 - main_output_loss: 13.3980 - aux_output_loss: 2.0990 - val_loss: 4.7234 - val_main_output_loss: 2.9343 - val_aux_output_loss: 3.5745\n",
      "Epoch 92/500\n",
      " - 0s - loss: 18.3185 - main_output_loss: 16.8126 - aux_output_loss: 2.1942 - val_loss: 4.6520 - val_main_output_loss: 2.8846 - val_aux_output_loss: 3.5134\n",
      "Epoch 93/500\n",
      " - 0s - loss: 14.8146 - main_output_loss: 13.3472 - aux_output_loss: 2.0646 - val_loss: 4.7051 - val_main_output_loss: 2.9558 - val_aux_output_loss: 3.4917\n",
      "Epoch 94/500\n",
      " - 0s - loss: 14.9715 - main_output_loss: 13.5214 - aux_output_loss: 2.0449 - val_loss: 4.7469 - val_main_output_loss: 3.0342 - val_aux_output_loss: 3.3787\n",
      "Epoch 95/500\n",
      " - 0s - loss: 14.5510 - main_output_loss: 13.1244 - aux_output_loss: 1.9884 - val_loss: 4.4269 - val_main_output_loss: 2.6986 - val_aux_output_loss: 3.4995\n",
      "Epoch 96/500\n",
      " - 0s - loss: 14.6775 - main_output_loss: 13.2623 - aux_output_loss: 1.9800 - val_loss: 4.4152 - val_main_output_loss: 2.7130 - val_aux_output_loss: 3.4291\n",
      "Epoch 97/500\n",
      " - 0s - loss: 14.7865 - main_output_loss: 13.3750 - aux_output_loss: 2.0101 - val_loss: 4.3820 - val_main_output_loss: 2.6923 - val_aux_output_loss: 3.4117\n",
      "Epoch 98/500\n",
      " - 0s - loss: 14.4339 - main_output_loss: 13.0436 - aux_output_loss: 1.9636 - val_loss: 4.4372 - val_main_output_loss: 2.7736 - val_aux_output_loss: 3.3329\n",
      "Epoch 99/500\n",
      " - 0s - loss: 14.8532 - main_output_loss: 13.4832 - aux_output_loss: 1.9186 - val_loss: 4.3844 - val_main_output_loss: 2.7350 - val_aux_output_loss: 3.3232\n",
      "Epoch 100/500\n",
      " - 0s - loss: 15.6870 - main_output_loss: 14.2851 - aux_output_loss: 2.1241 - val_loss: 4.3164 - val_main_output_loss: 2.6753 - val_aux_output_loss: 3.3313\n",
      "Epoch 101/500\n",
      " - 0s - loss: 2515.3678 - main_output_loss: 2473.2651 - aux_output_loss: 205.6793 - val_loss: 4.3237 - val_main_output_loss: 2.7048 - val_aux_output_loss: 3.2692\n",
      "Epoch 102/500\n",
      " - 0s - loss: 36.9499 - main_output_loss: 35.3096 - aux_output_loss: 3.4148 - val_loss: 4.2307 - val_main_output_loss: 2.6146 - val_aux_output_loss: 3.2928\n",
      "Epoch 103/500\n",
      " - 0s - loss: 16.5319 - main_output_loss: 15.1597 - aux_output_loss: 2.1185 - val_loss: 4.1548 - val_main_output_loss: 2.5552 - val_aux_output_loss: 3.2696\n",
      "Epoch 104/500\n",
      " - 0s - loss: 14.0499 - main_output_loss: 12.7414 - aux_output_loss: 1.8614 - val_loss: 4.3530 - val_main_output_loss: 2.7929 - val_aux_output_loss: 3.1081\n",
      "Epoch 105/500\n",
      " - 0s - loss: 14.1017 - main_output_loss: 12.8132 - aux_output_loss: 1.7991 - val_loss: 4.1719 - val_main_output_loss: 2.6126 - val_aux_output_loss: 3.1542\n",
      "Epoch 106/500\n",
      " - 0s - loss: 14.4272 - main_output_loss: 13.1410 - aux_output_loss: 1.8312 - val_loss: 4.2631 - val_main_output_loss: 2.7239 - val_aux_output_loss: 3.0907\n",
      "Epoch 107/500\n",
      " - 0s - loss: 20.0491 - main_output_loss: 18.6780 - aux_output_loss: 2.2840 - val_loss: 4.1984 - val_main_output_loss: 2.6702 - val_aux_output_loss: 3.0563\n",
      "Epoch 108/500\n",
      " - 0s - loss: 16.3255 - main_output_loss: 15.0081 - aux_output_loss: 2.0394 - val_loss: 4.3157 - val_main_output_loss: 2.8129 - val_aux_output_loss: 2.9636\n",
      "Epoch 109/500\n",
      " - 0s - loss: 14.1214 - main_output_loss: 12.8639 - aux_output_loss: 1.7695 - val_loss: 3.9967 - val_main_output_loss: 2.4922 - val_aux_output_loss: 3.0118\n",
      "Epoch 110/500\n",
      " - 0s - loss: 14.1047 - main_output_loss: 12.8611 - aux_output_loss: 1.7501 - val_loss: 3.9747 - val_main_output_loss: 2.4796 - val_aux_output_loss: 3.0008\n",
      "Epoch 111/500\n",
      " - 0s - loss: 13.9392 - main_output_loss: 12.7070 - aux_output_loss: 1.7071 - val_loss: 3.9739 - val_main_output_loss: 2.4802 - val_aux_output_loss: 3.0052\n",
      "Epoch 112/500\n",
      " - 0s - loss: 14.4032 - main_output_loss: 13.1517 - aux_output_loss: 1.8337 - val_loss: 4.1330 - val_main_output_loss: 2.6565 - val_aux_output_loss: 2.9543\n",
      "Epoch 113/500\n",
      " - 0s - loss: 13.8082 - main_output_loss: 12.5872 - aux_output_loss: 1.7183 - val_loss: 4.0925 - val_main_output_loss: 2.6240 - val_aux_output_loss: 2.9522\n",
      "Epoch 114/500\n",
      " - 0s - loss: 13.8409 - main_output_loss: 12.6366 - aux_output_loss: 1.6748 - val_loss: 4.1195 - val_main_output_loss: 2.6669 - val_aux_output_loss: 2.9180\n",
      "Epoch 115/500\n",
      " - 0s - loss: 13.7349 - main_output_loss: 12.5292 - aux_output_loss: 1.7084 - val_loss: 4.1277 - val_main_output_loss: 2.6917 - val_aux_output_loss: 2.8549\n",
      "Epoch 116/500\n",
      " - 0s - loss: 13.4860 - main_output_loss: 12.2845 - aux_output_loss: 1.7030 - val_loss: 3.8093 - val_main_output_loss: 2.3584 - val_aux_output_loss: 2.9442\n",
      "Epoch 117/500\n",
      " - 0s - loss: 13.4554 - main_output_loss: 12.2605 - aux_output_loss: 1.7060 - val_loss: 3.6475 - val_main_output_loss: 2.1997 - val_aux_output_loss: 2.9740\n",
      "Epoch 118/500\n",
      " - 0s - loss: 13.3660 - main_output_loss: 12.1874 - aux_output_loss: 1.6723 - val_loss: 3.9884 - val_main_output_loss: 2.5839 - val_aux_output_loss: 2.8040\n",
      "Epoch 119/500\n",
      " - 0s - loss: 13.7213 - main_output_loss: 12.5462 - aux_output_loss: 1.6764 - val_loss: 3.9895 - val_main_output_loss: 2.5961 - val_aux_output_loss: 2.7547\n",
      "Epoch 120/500\n",
      " - 0s - loss: 14.8900 - main_output_loss: 13.6982 - aux_output_loss: 1.7940 - val_loss: 3.8435 - val_main_output_loss: 2.4473 - val_aux_output_loss: 2.8197\n",
      "Epoch 121/500\n",
      " - 0s - loss: 13.6496 - main_output_loss: 12.4911 - aux_output_loss: 1.6610 - val_loss: 3.8094 - val_main_output_loss: 2.4169 - val_aux_output_loss: 2.8307\n",
      "Epoch 122/500\n",
      " - 0s - loss: 13.5519 - main_output_loss: 12.4069 - aux_output_loss: 1.6243 - val_loss: 3.9705 - val_main_output_loss: 2.5995 - val_aux_output_loss: 2.7478\n",
      "Epoch 123/500\n",
      " - 0s - loss: 13.6980 - main_output_loss: 12.5655 - aux_output_loss: 1.5816 - val_loss: 4.1663 - val_main_output_loss: 2.8243 - val_aux_output_loss: 2.6159\n",
      "Epoch 124/500\n",
      " - 0s - loss: 13.9461 - main_output_loss: 12.7972 - aux_output_loss: 1.6863 - val_loss: 3.8629 - val_main_output_loss: 2.5125 - val_aux_output_loss: 2.6831\n",
      "Epoch 125/500\n",
      " - 0s - loss: 13.2713 - main_output_loss: 12.1458 - aux_output_loss: 1.5838 - val_loss: 3.7221 - val_main_output_loss: 2.3626 - val_aux_output_loss: 2.7422\n",
      "Epoch 126/500\n",
      " - 0s - loss: 13.3798 - main_output_loss: 12.2593 - aux_output_loss: 1.5938 - val_loss: 3.9807 - val_main_output_loss: 2.6526 - val_aux_output_loss: 2.6354\n",
      "Epoch 127/500\n",
      " - 0s - loss: 13.2800 - main_output_loss: 12.1692 - aux_output_loss: 1.5726 - val_loss: 3.8103 - val_main_output_loss: 2.4836 - val_aux_output_loss: 2.6439\n",
      "Epoch 128/500\n",
      " - 0s - loss: 13.4123 - main_output_loss: 12.3127 - aux_output_loss: 1.5459 - val_loss: 3.7451 - val_main_output_loss: 2.4247 - val_aux_output_loss: 2.6429\n",
      "Epoch 129/500\n",
      " - 0s - loss: 422.8840 - main_output_loss: 416.4541 - aux_output_loss: 28.2160 - val_loss: 3.6857 - val_main_output_loss: 2.3741 - val_aux_output_loss: 2.6228\n",
      "Epoch 130/500\n",
      " - 0s - loss: 13.4071 - main_output_loss: 12.3185 - aux_output_loss: 1.5439 - val_loss: 3.5869 - val_main_output_loss: 2.2746 - val_aux_output_loss: 2.6522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/500\n",
      " - 0s - loss: 13.4764 - main_output_loss: 12.3980 - aux_output_loss: 1.5230 - val_loss: 3.8587 - val_main_output_loss: 2.5702 - val_aux_output_loss: 2.5599\n",
      "Epoch 132/500\n",
      " - 0s - loss: 13.4760 - main_output_loss: 12.3913 - aux_output_loss: 1.5568 - val_loss: 3.9569 - val_main_output_loss: 2.6796 - val_aux_output_loss: 2.5216\n",
      "Epoch 133/500\n",
      " - 0s - loss: 12.7518 - main_output_loss: 11.6836 - aux_output_loss: 1.4919 - val_loss: 3.6450 - val_main_output_loss: 2.3593 - val_aux_output_loss: 2.5710\n",
      "Epoch 134/500\n",
      " - 0s - loss: 13.0411 - main_output_loss: 11.9774 - aux_output_loss: 1.5068 - val_loss: 3.6766 - val_main_output_loss: 2.3998 - val_aux_output_loss: 2.5666\n",
      "Epoch 135/500\n",
      " - 0s - loss: 13.4242 - main_output_loss: 12.3669 - aux_output_loss: 1.4944 - val_loss: 3.8643 - val_main_output_loss: 2.6070 - val_aux_output_loss: 2.4805\n",
      "Epoch 136/500\n",
      " - 0s - loss: 14.5191 - main_output_loss: 13.4312 - aux_output_loss: 1.6621 - val_loss: 3.6541 - val_main_output_loss: 2.3985 - val_aux_output_loss: 2.4860\n",
      "Epoch 137/500\n",
      " - 0s - loss: 12.6653 - main_output_loss: 11.6145 - aux_output_loss: 1.4910 - val_loss: 3.8846 - val_main_output_loss: 2.6500 - val_aux_output_loss: 2.4064\n",
      "Epoch 138/500\n",
      " - 0s - loss: 12.8117 - main_output_loss: 11.7685 - aux_output_loss: 1.4856 - val_loss: 3.7083 - val_main_output_loss: 2.4731 - val_aux_output_loss: 2.4473\n",
      "Epoch 139/500\n",
      " - 0s - loss: 12.9052 - main_output_loss: 11.8675 - aux_output_loss: 1.4775 - val_loss: 3.5975 - val_main_output_loss: 2.3523 - val_aux_output_loss: 2.4971\n",
      "Epoch 140/500\n",
      " - 0s - loss: 12.8331 - main_output_loss: 11.8071 - aux_output_loss: 1.4406 - val_loss: 3.6769 - val_main_output_loss: 2.4481 - val_aux_output_loss: 2.4491\n",
      "Epoch 141/500\n",
      " - 0s - loss: 12.8812 - main_output_loss: 11.8660 - aux_output_loss: 1.4147 - val_loss: 3.5755 - val_main_output_loss: 2.3504 - val_aux_output_loss: 2.4690\n",
      "Epoch 142/500\n",
      " - 0s - loss: 12.7500 - main_output_loss: 11.7374 - aux_output_loss: 1.4315 - val_loss: 3.7583 - val_main_output_loss: 2.5548 - val_aux_output_loss: 2.3768\n",
      "Epoch 143/500\n",
      " - 0s - loss: 12.8160 - main_output_loss: 11.8073 - aux_output_loss: 1.4213 - val_loss: 3.6931 - val_main_output_loss: 2.4963 - val_aux_output_loss: 2.3532\n",
      "Epoch 144/500\n",
      " - 0s - loss: 12.7726 - main_output_loss: 11.7693 - aux_output_loss: 1.4083 - val_loss: 3.5084 - val_main_output_loss: 2.3026 - val_aux_output_loss: 2.4074\n",
      "Epoch 145/500\n",
      " - 0s - loss: 13.1320 - main_output_loss: 12.1255 - aux_output_loss: 1.4431 - val_loss: 3.4092 - val_main_output_loss: 2.1990 - val_aux_output_loss: 2.4403\n",
      "Epoch 146/500\n",
      " - 0s - loss: 12.6902 - main_output_loss: 11.6924 - aux_output_loss: 1.4131 - val_loss: 3.5727 - val_main_output_loss: 2.3825 - val_aux_output_loss: 2.3629\n",
      "Epoch 147/500\n",
      " - 0s - loss: 12.6741 - main_output_loss: 11.6871 - aux_output_loss: 1.3857 - val_loss: 3.5886 - val_main_output_loss: 2.4033 - val_aux_output_loss: 2.3701\n",
      "Epoch 148/500\n",
      " - 0s - loss: 12.5325 - main_output_loss: 11.5489 - aux_output_loss: 1.3805 - val_loss: 3.6633 - val_main_output_loss: 2.4888 - val_aux_output_loss: 2.3263\n",
      "Epoch 149/500\n",
      " - 0s - loss: 12.9832 - main_output_loss: 11.9915 - aux_output_loss: 1.4225 - val_loss: 3.6065 - val_main_output_loss: 2.4351 - val_aux_output_loss: 2.3069\n",
      "Epoch 150/500\n",
      " - 0s - loss: 12.4972 - main_output_loss: 11.5273 - aux_output_loss: 1.3487 - val_loss: 3.6611 - val_main_output_loss: 2.5078 - val_aux_output_loss: 2.2660\n",
      "Epoch 151/500\n",
      " - 0s - loss: 13.3689 - main_output_loss: 12.3756 - aux_output_loss: 1.4919 - val_loss: 3.5443 - val_main_output_loss: 2.3851 - val_aux_output_loss: 2.2978\n",
      "Epoch 152/500\n",
      " - 0s - loss: 12.8167 - main_output_loss: 11.8455 - aux_output_loss: 1.3926 - val_loss: 3.5270 - val_main_output_loss: 2.3771 - val_aux_output_loss: 2.2891\n",
      "Epoch 153/500\n",
      " - 0s - loss: 12.6936 - main_output_loss: 11.7303 - aux_output_loss: 1.3721 - val_loss: 3.4981 - val_main_output_loss: 2.3448 - val_aux_output_loss: 2.3157\n",
      "Epoch 154/500\n",
      " - 0s - loss: 12.5628 - main_output_loss: 11.6060 - aux_output_loss: 1.3655 - val_loss: 3.6057 - val_main_output_loss: 2.4660 - val_aux_output_loss: 2.2657\n",
      "Epoch 155/500\n",
      " - 0s - loss: 12.6018 - main_output_loss: 11.6496 - aux_output_loss: 1.3531 - val_loss: 3.5903 - val_main_output_loss: 2.4537 - val_aux_output_loss: 2.2540\n",
      "Epoch 156/500\n",
      " - 0s - loss: 12.4007 - main_output_loss: 11.4592 - aux_output_loss: 1.3160 - val_loss: 3.7212 - val_main_output_loss: 2.6004 - val_aux_output_loss: 2.2026\n",
      "Epoch 157/500\n",
      " - 0s - loss: 12.2057 - main_output_loss: 11.2655 - aux_output_loss: 1.3235 - val_loss: 3.2696 - val_main_output_loss: 2.1286 - val_aux_output_loss: 2.3262\n",
      "Epoch 158/500\n",
      " - 0s - loss: 12.2284 - main_output_loss: 11.2923 - aux_output_loss: 1.3174 - val_loss: 3.4902 - val_main_output_loss: 2.3730 - val_aux_output_loss: 2.2111\n",
      "Epoch 159/500\n",
      " - 0s - loss: 12.5027 - main_output_loss: 11.5689 - aux_output_loss: 1.3111 - val_loss: 3.7628 - val_main_output_loss: 2.6681 - val_aux_output_loss: 2.1105\n",
      "Epoch 160/500\n",
      " - 0s - loss: 12.4271 - main_output_loss: 11.4963 - aux_output_loss: 1.3033 - val_loss: 3.5936 - val_main_output_loss: 2.4960 - val_aux_output_loss: 2.1329\n",
      "Epoch 161/500\n",
      " - 0s - loss: 12.0956 - main_output_loss: 11.1659 - aux_output_loss: 1.3064 - val_loss: 3.4060 - val_main_output_loss: 2.2987 - val_aux_output_loss: 2.1926\n",
      "Epoch 162/500\n",
      " - 0s - loss: 12.1260 - main_output_loss: 11.2046 - aux_output_loss: 1.2868 - val_loss: 3.5733 - val_main_output_loss: 2.4793 - val_aux_output_loss: 2.1299\n",
      "Epoch 163/500\n",
      " - 0s - loss: 12.3891 - main_output_loss: 11.4734 - aux_output_loss: 1.2651 - val_loss: 3.7431 - val_main_output_loss: 2.6604 - val_aux_output_loss: 2.1053\n",
      "Epoch 164/500\n",
      " - 0s - loss: 16.8642 - main_output_loss: 15.8757 - aux_output_loss: 1.6566 - val_loss: 4.0105 - val_main_output_loss: 2.9452 - val_aux_output_loss: 2.0278\n",
      "Epoch 165/500\n",
      " - 0s - loss: 11.7868 - main_output_loss: 10.8784 - aux_output_loss: 1.2730 - val_loss: 3.4908 - val_main_output_loss: 2.4134 - val_aux_output_loss: 2.1257\n",
      "Epoch 166/500\n",
      " - 0s - loss: 12.0823 - main_output_loss: 11.1784 - aux_output_loss: 1.2691 - val_loss: 3.5342 - val_main_output_loss: 2.4640 - val_aux_output_loss: 2.0987\n",
      "Epoch 167/500\n",
      " - 0s - loss: 12.2684 - main_output_loss: 11.3699 - aux_output_loss: 1.2475 - val_loss: 3.2704 - val_main_output_loss: 2.1895 - val_aux_output_loss: 2.1509\n",
      "Epoch 168/500\n",
      " - 0s - loss: 12.1581 - main_output_loss: 11.2636 - aux_output_loss: 1.2370 - val_loss: 3.4448 - val_main_output_loss: 2.3796 - val_aux_output_loss: 2.0841\n",
      "Epoch 169/500\n",
      " - 0s - loss: 11.9913 - main_output_loss: 11.0982 - aux_output_loss: 1.2352 - val_loss: 3.3086 - val_main_output_loss: 2.2486 - val_aux_output_loss: 2.0665\n",
      "Epoch 170/500\n",
      " - 0s - loss: 11.9550 - main_output_loss: 11.0658 - aux_output_loss: 1.2371 - val_loss: 3.5050 - val_main_output_loss: 2.4583 - val_aux_output_loss: 2.0133\n",
      "Epoch 171/500\n",
      " - 0s - loss: 1502.6404 - main_output_loss: 1482.7876 - aux_output_loss: 96.0743 - val_loss: 3.4825 - val_main_output_loss: 2.4396 - val_aux_output_loss: 2.0194\n",
      "Epoch 172/500\n",
      " - 0s - loss: 11.7859 - main_output_loss: 10.9072 - aux_output_loss: 1.2193 - val_loss: 3.3778 - val_main_output_loss: 2.3277 - val_aux_output_loss: 2.0682\n",
      "Epoch 173/500\n",
      " - 0s - loss: 11.8969 - main_output_loss: 11.0206 - aux_output_loss: 1.2191 - val_loss: 3.5472 - val_main_output_loss: 2.5149 - val_aux_output_loss: 2.0023\n",
      "Epoch 174/500\n",
      " - 0s - loss: 11.9007 - main_output_loss: 11.0316 - aux_output_loss: 1.2047 - val_loss: 3.4916 - val_main_output_loss: 2.4591 - val_aux_output_loss: 2.0099\n",
      "Epoch 175/500\n",
      " - 0s - loss: 12.4406 - main_output_loss: 11.5727 - aux_output_loss: 1.1972 - val_loss: 3.5330 - val_main_output_loss: 2.5106 - val_aux_output_loss: 1.9625\n",
      "Epoch 176/500\n",
      " - 0s - loss: 11.8614 - main_output_loss: 10.9995 - aux_output_loss: 1.1788 - val_loss: 3.5420 - val_main_output_loss: 2.5216 - val_aux_output_loss: 1.9702\n",
      "Epoch 177/500\n",
      " - 0s - loss: 11.8999 - main_output_loss: 11.0353 - aux_output_loss: 1.1979 - val_loss: 3.4404 - val_main_output_loss: 2.4210 - val_aux_output_loss: 1.9612\n",
      "Epoch 178/500\n",
      " - 0s - loss: 11.6039 - main_output_loss: 10.7495 - aux_output_loss: 1.1629 - val_loss: 3.3839 - val_main_output_loss: 2.3706 - val_aux_output_loss: 1.9620\n",
      "Epoch 179/500\n",
      " - 0s - loss: 11.5298 - main_output_loss: 10.6800 - aux_output_loss: 1.1591 - val_loss: 3.3205 - val_main_output_loss: 2.3055 - val_aux_output_loss: 1.9727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/500\n",
      " - 0s - loss: 12.0222 - main_output_loss: 11.1724 - aux_output_loss: 1.1741 - val_loss: 3.3919 - val_main_output_loss: 2.3856 - val_aux_output_loss: 1.9452\n",
      "Epoch 181/500\n",
      " - 0s - loss: 11.4969 - main_output_loss: 10.6531 - aux_output_loss: 1.1555 - val_loss: 3.5709 - val_main_output_loss: 2.5776 - val_aux_output_loss: 1.8976\n",
      "Epoch 182/500\n",
      " - 0s - loss: 12.0436 - main_output_loss: 11.2030 - aux_output_loss: 1.1505 - val_loss: 3.6703 - val_main_output_loss: 2.6851 - val_aux_output_loss: 1.8613\n",
      "Epoch 183/500\n",
      " - 0s - loss: 11.5578 - main_output_loss: 10.7237 - aux_output_loss: 1.1385 - val_loss: 3.4726 - val_main_output_loss: 2.4871 - val_aux_output_loss: 1.8871\n",
      "Epoch 184/500\n",
      " - 0s - loss: 11.9105 - main_output_loss: 11.0763 - aux_output_loss: 1.1510 - val_loss: 3.2355 - val_main_output_loss: 2.2424 - val_aux_output_loss: 1.9308\n",
      "Epoch 185/500\n",
      " - 0s - loss: 11.5996 - main_output_loss: 10.7664 - aux_output_loss: 1.1581 - val_loss: 3.2867 - val_main_output_loss: 2.3041 - val_aux_output_loss: 1.9050\n",
      "Epoch 186/500\n",
      " - 0s - loss: 11.0796 - main_output_loss: 10.2570 - aux_output_loss: 1.1197 - val_loss: 3.2246 - val_main_output_loss: 2.2416 - val_aux_output_loss: 1.9045\n",
      "Epoch 187/500\n",
      " - 0s - loss: 11.3262 - main_output_loss: 10.5030 - aux_output_loss: 1.1211 - val_loss: 3.2943 - val_main_output_loss: 2.3160 - val_aux_output_loss: 1.8861\n",
      "Epoch 188/500\n",
      " - 0s - loss: 11.8002 - main_output_loss: 10.9797 - aux_output_loss: 1.1182 - val_loss: 3.2139 - val_main_output_loss: 2.2386 - val_aux_output_loss: 1.8872\n",
      "Epoch 189/500\n",
      " - 0s - loss: 11.6728 - main_output_loss: 10.8557 - aux_output_loss: 1.1137 - val_loss: 3.1055 - val_main_output_loss: 2.1259 - val_aux_output_loss: 1.9112\n",
      "Epoch 190/500\n",
      " - 0s - loss: 11.5043 - main_output_loss: 10.6886 - aux_output_loss: 1.1080 - val_loss: 3.3763 - val_main_output_loss: 2.4151 - val_aux_output_loss: 1.8432\n",
      "Epoch 191/500\n",
      " - 0s - loss: 11.2684 - main_output_loss: 10.4622 - aux_output_loss: 1.0920 - val_loss: 3.2625 - val_main_output_loss: 2.3055 - val_aux_output_loss: 1.8388\n",
      "Epoch 192/500\n",
      " - 0s - loss: 11.0436 - main_output_loss: 10.2368 - aux_output_loss: 1.1063 - val_loss: 3.2586 - val_main_output_loss: 2.3040 - val_aux_output_loss: 1.8267\n",
      "Epoch 193/500\n",
      " - 0s - loss: 11.5472 - main_output_loss: 10.7502 - aux_output_loss: 1.0707 - val_loss: 3.3654 - val_main_output_loss: 2.4177 - val_aux_output_loss: 1.8276\n",
      "Epoch 194/500\n",
      " - 0s - loss: 11.2852 - main_output_loss: 10.4882 - aux_output_loss: 1.0831 - val_loss: 3.1660 - val_main_output_loss: 2.2098 - val_aux_output_loss: 1.8522\n",
      "Epoch 195/500\n",
      " - 0s - loss: 11.2482 - main_output_loss: 10.4522 - aux_output_loss: 1.0715 - val_loss: 3.6712 - val_main_output_loss: 2.7430 - val_aux_output_loss: 1.7356\n",
      "Epoch 196/500\n",
      " - 0s - loss: 11.3232 - main_output_loss: 10.5273 - aux_output_loss: 1.0837 - val_loss: 3.0044 - val_main_output_loss: 2.0482 - val_aux_output_loss: 1.8801\n",
      "Epoch 197/500\n",
      " - 0s - loss: 11.3240 - main_output_loss: 10.5348 - aux_output_loss: 1.0631 - val_loss: 3.1624 - val_main_output_loss: 2.2270 - val_aux_output_loss: 1.7953\n",
      "Epoch 198/500\n",
      " - 0s - loss: 11.1842 - main_output_loss: 10.4002 - aux_output_loss: 1.0565 - val_loss: 3.0882 - val_main_output_loss: 2.1522 - val_aux_output_loss: 1.8111\n",
      "Epoch 199/500\n",
      " - 0s - loss: 11.1206 - main_output_loss: 10.3386 - aux_output_loss: 1.0560 - val_loss: 3.3354 - val_main_output_loss: 2.4116 - val_aux_output_loss: 1.7530\n",
      "Epoch 200/500\n",
      " - 0s - loss: 11.1264 - main_output_loss: 10.3522 - aux_output_loss: 1.0389 - val_loss: 3.3614 - val_main_output_loss: 2.4470 - val_aux_output_loss: 1.7318\n",
      "Epoch 201/500\n",
      " - 0s - loss: 11.3373 - main_output_loss: 10.5641 - aux_output_loss: 1.0314 - val_loss: 3.3483 - val_main_output_loss: 2.4384 - val_aux_output_loss: 1.7171\n",
      "Epoch 202/500\n",
      " - 0s - loss: 11.0433 - main_output_loss: 10.2740 - aux_output_loss: 1.0208 - val_loss: 3.1917 - val_main_output_loss: 2.2768 - val_aux_output_loss: 1.7391\n",
      "Epoch 203/500\n",
      " - 0s - loss: 10.9984 - main_output_loss: 10.2303 - aux_output_loss: 1.0255 - val_loss: 3.0493 - val_main_output_loss: 2.1349 - val_aux_output_loss: 1.7487\n",
      "Epoch 204/500\n",
      " - 0s - loss: 10.9431 - main_output_loss: 10.1840 - aux_output_loss: 1.0053 - val_loss: 3.1270 - val_main_output_loss: 2.2223 - val_aux_output_loss: 1.7257\n",
      "Epoch 205/500\n",
      " - 0s - loss: 11.3827 - main_output_loss: 10.6242 - aux_output_loss: 1.0090 - val_loss: 3.1737 - val_main_output_loss: 2.2772 - val_aux_output_loss: 1.6772\n",
      "Epoch 206/500\n",
      " - 0s - loss: 10.8809 - main_output_loss: 10.1300 - aux_output_loss: 0.9805 - val_loss: 3.0604 - val_main_output_loss: 2.1623 - val_aux_output_loss: 1.7177\n",
      "Epoch 207/500\n",
      " - 0s - loss: 11.0227 - main_output_loss: 10.2735 - aux_output_loss: 0.9949 - val_loss: 3.1234 - val_main_output_loss: 2.2358 - val_aux_output_loss: 1.6779\n",
      "Epoch 208/500\n",
      " - 0s - loss: 11.1001 - main_output_loss: 10.3511 - aux_output_loss: 0.9917 - val_loss: 2.9456 - val_main_output_loss: 2.0531 - val_aux_output_loss: 1.6958\n",
      "Epoch 209/500\n",
      " - 0s - loss: 10.7262 - main_output_loss: 9.9846 - aux_output_loss: 0.9785 - val_loss: 3.1620 - val_main_output_loss: 2.2819 - val_aux_output_loss: 1.6795\n",
      "Epoch 210/500\n",
      " - 0s - loss: 10.9672 - main_output_loss: 10.2281 - aux_output_loss: 0.9834 - val_loss: 3.4961 - val_main_output_loss: 2.6287 - val_aux_output_loss: 1.6051\n",
      "Epoch 211/500\n",
      " - 0s - loss: 10.8547 - main_output_loss: 10.1205 - aux_output_loss: 0.9666 - val_loss: 3.4675 - val_main_output_loss: 2.6071 - val_aux_output_loss: 1.5992\n",
      "Epoch 212/500\n",
      " - 0s - loss: 10.9362 - main_output_loss: 10.2055 - aux_output_loss: 0.9610 - val_loss: 3.0536 - val_main_output_loss: 2.1810 - val_aux_output_loss: 1.6660\n",
      "Epoch 213/500\n",
      " - 0s - loss: 10.8789 - main_output_loss: 10.1518 - aux_output_loss: 0.9639 - val_loss: 3.2216 - val_main_output_loss: 2.3572 - val_aux_output_loss: 1.6479\n",
      "Epoch 214/500\n",
      " - 0s - loss: 10.9317 - main_output_loss: 10.2022 - aux_output_loss: 0.9885 - val_loss: 3.1718 - val_main_output_loss: 2.3082 - val_aux_output_loss: 1.6520\n",
      "Epoch 215/500\n",
      " - 0s - loss: 10.6261 - main_output_loss: 9.9091 - aux_output_loss: 0.9536 - val_loss: 3.2372 - val_main_output_loss: 2.3907 - val_aux_output_loss: 1.6042\n",
      "Epoch 216/500\n",
      " - 0s - loss: 10.9352 - main_output_loss: 10.2193 - aux_output_loss: 0.9560 - val_loss: 2.9229 - val_main_output_loss: 2.0610 - val_aux_output_loss: 1.6666\n",
      "Epoch 217/500\n",
      " - 0s - loss: 10.6117 - main_output_loss: 9.8938 - aux_output_loss: 0.9619 - val_loss: 3.1283 - val_main_output_loss: 2.2869 - val_aux_output_loss: 1.5785\n",
      "Epoch 218/500\n",
      " - 1s - loss: 10.7800 - main_output_loss: 10.0739 - aux_output_loss: 0.9249 - val_loss: 3.1038 - val_main_output_loss: 2.2588 - val_aux_output_loss: 1.5994\n",
      "Epoch 219/500\n",
      " - 0s - loss: 10.6706 - main_output_loss: 9.9633 - aux_output_loss: 0.9318 - val_loss: 2.9538 - val_main_output_loss: 2.1070 - val_aux_output_loss: 1.6276\n",
      "Epoch 220/500\n",
      " - 0s - loss: 10.6786 - main_output_loss: 9.9768 - aux_output_loss: 0.9267 - val_loss: 2.9629 - val_main_output_loss: 2.1212 - val_aux_output_loss: 1.6224\n",
      "Epoch 221/500\n",
      " - 0s - loss: 10.5532 - main_output_loss: 9.8528 - aux_output_loss: 0.9152 - val_loss: 3.3947 - val_main_output_loss: 2.5747 - val_aux_output_loss: 1.5014\n",
      "Epoch 222/500\n",
      " - 0s - loss: 10.4865 - main_output_loss: 9.7906 - aux_output_loss: 0.8947 - val_loss: 3.1333 - val_main_output_loss: 2.3114 - val_aux_output_loss: 1.5277\n",
      "Epoch 223/500\n",
      " - 0s - loss: 10.3305 - main_output_loss: 9.6366 - aux_output_loss: 0.9044 - val_loss: 3.0095 - val_main_output_loss: 2.1862 - val_aux_output_loss: 1.5535\n",
      "Epoch 224/500\n",
      " - 0s - loss: 10.6331 - main_output_loss: 9.9347 - aux_output_loss: 0.9475 - val_loss: 2.9533 - val_main_output_loss: 2.1291 - val_aux_output_loss: 1.5690\n",
      "Epoch 225/500\n",
      " - 0s - loss: 10.3841 - main_output_loss: 9.6945 - aux_output_loss: 0.9057 - val_loss: 2.9362 - val_main_output_loss: 2.1196 - val_aux_output_loss: 1.5377\n",
      "Epoch 226/500\n",
      " - 0s - loss: 10.3640 - main_output_loss: 9.6821 - aux_output_loss: 0.8761 - val_loss: 3.4416 - val_main_output_loss: 2.6471 - val_aux_output_loss: 1.4293\n",
      "Epoch 227/500\n",
      " - 0s - loss: 10.6353 - main_output_loss: 9.9567 - aux_output_loss: 0.8730 - val_loss: 3.1174 - val_main_output_loss: 2.3083 - val_aux_output_loss: 1.5108\n",
      "Epoch 228/500\n",
      " - 0s - loss: 10.3669 - main_output_loss: 9.6877 - aux_output_loss: 0.8844 - val_loss: 3.2455 - val_main_output_loss: 2.4475 - val_aux_output_loss: 1.4786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      " - 0s - loss: 10.5666 - main_output_loss: 9.8901 - aux_output_loss: 0.8885 - val_loss: 2.8266 - val_main_output_loss: 2.0111 - val_aux_output_loss: 1.5824\n",
      "Epoch 230/500\n",
      " - 0s - loss: 10.5706 - main_output_loss: 9.8953 - aux_output_loss: 0.8880 - val_loss: 3.1575 - val_main_output_loss: 2.3677 - val_aux_output_loss: 1.4457\n",
      "Epoch 231/500\n",
      " - 0s - loss: 10.3509 - main_output_loss: 9.6815 - aux_output_loss: 0.8566 - val_loss: 2.9673 - val_main_output_loss: 2.1688 - val_aux_output_loss: 1.5094\n",
      "Epoch 232/500\n",
      " - 0s - loss: 10.4163 - main_output_loss: 9.7492 - aux_output_loss: 0.8652 - val_loss: 3.1232 - val_main_output_loss: 2.3402 - val_aux_output_loss: 1.4452\n",
      "Epoch 233/500\n",
      " - 0s - loss: 10.0374 - main_output_loss: 9.3770 - aux_output_loss: 0.8417 - val_loss: 2.9761 - val_main_output_loss: 2.1897 - val_aux_output_loss: 1.4672\n",
      "Epoch 234/500\n",
      " - 0s - loss: 10.4972 - main_output_loss: 9.8360 - aux_output_loss: 0.8604 - val_loss: 2.9896 - val_main_output_loss: 2.2092 - val_aux_output_loss: 1.4340\n",
      "Epoch 235/500\n",
      " - 0s - loss: 10.3771 - main_output_loss: 9.7146 - aux_output_loss: 0.8559 - val_loss: 2.7105 - val_main_output_loss: 1.9254 - val_aux_output_loss: 1.4675\n",
      "Epoch 236/500\n",
      " - 0s - loss: 10.2547 - main_output_loss: 9.5975 - aux_output_loss: 0.8419 - val_loss: 3.1586 - val_main_output_loss: 2.4014 - val_aux_output_loss: 1.3369\n",
      "Epoch 237/500\n",
      " - 0s - loss: 10.0131 - main_output_loss: 9.3633 - aux_output_loss: 0.8289 - val_loss: 2.8847 - val_main_output_loss: 2.1260 - val_aux_output_loss: 1.3845\n",
      "Epoch 238/500\n",
      " - 0s - loss: 10.8834 - main_output_loss: 10.2218 - aux_output_loss: 0.9115 - val_loss: 3.1384 - val_main_output_loss: 2.3889 - val_aux_output_loss: 1.3283\n",
      "Epoch 239/500\n",
      " - 0s - loss: 9.9368 - main_output_loss: 9.2952 - aux_output_loss: 0.8088 - val_loss: 2.7521 - val_main_output_loss: 1.9865 - val_aux_output_loss: 1.4265\n",
      "Epoch 240/500\n",
      " - 0s - loss: 9.8224 - main_output_loss: 9.1823 - aux_output_loss: 0.8096 - val_loss: 2.8806 - val_main_output_loss: 2.1270 - val_aux_output_loss: 1.3713\n",
      "Epoch 241/500\n",
      " - 0s - loss: 9.8887 - main_output_loss: 9.2481 - aux_output_loss: 0.8262 - val_loss: 2.8482 - val_main_output_loss: 2.0963 - val_aux_output_loss: 1.3820\n",
      "Epoch 242/500\n",
      " - 0s - loss: 9.7790 - main_output_loss: 9.1458 - aux_output_loss: 0.8136 - val_loss: 2.9042 - val_main_output_loss: 2.1642 - val_aux_output_loss: 1.3408\n",
      "Epoch 243/500\n",
      " - 0s - loss: 10.1740 - main_output_loss: 9.5435 - aux_output_loss: 0.8004 - val_loss: 3.0419 - val_main_output_loss: 2.3042 - val_aux_output_loss: 1.3120\n",
      "Epoch 244/500\n",
      " - 0s - loss: 9.7960 - main_output_loss: 9.1673 - aux_output_loss: 0.8030 - val_loss: 2.8410 - val_main_output_loss: 2.1008 - val_aux_output_loss: 1.3472\n",
      "Epoch 245/500\n",
      " - 0s - loss: 10.5272 - main_output_loss: 9.8897 - aux_output_loss: 0.8433 - val_loss: 2.7864 - val_main_output_loss: 2.0477 - val_aux_output_loss: 1.3504\n",
      "Epoch 246/500\n",
      " - 0s - loss: 9.7333 - main_output_loss: 9.1129 - aux_output_loss: 0.7854 - val_loss: 2.7474 - val_main_output_loss: 2.0131 - val_aux_output_loss: 1.3541\n",
      "Epoch 247/500\n",
      " - 0s - loss: 9.8513 - main_output_loss: 9.2379 - aux_output_loss: 0.7654 - val_loss: 3.0067 - val_main_output_loss: 2.2884 - val_aux_output_loss: 1.2982\n",
      "Epoch 248/500\n",
      " - 0s - loss: 9.8086 - main_output_loss: 9.1998 - aux_output_loss: 0.7634 - val_loss: 2.9490 - val_main_output_loss: 2.2343 - val_aux_output_loss: 1.2781\n",
      "Epoch 249/500\n",
      " - 0s - loss: 9.6861 - main_output_loss: 9.0797 - aux_output_loss: 0.7593 - val_loss: 2.8244 - val_main_output_loss: 2.1070 - val_aux_output_loss: 1.3031\n",
      "Epoch 250/500\n",
      " - 0s - loss: 9.9787 - main_output_loss: 9.3726 - aux_output_loss: 0.7569 - val_loss: 2.7739 - val_main_output_loss: 2.0566 - val_aux_output_loss: 1.2973\n",
      "Epoch 251/500\n",
      " - 0s - loss: 9.5201 - main_output_loss: 8.9157 - aux_output_loss: 0.7590 - val_loss: 2.7751 - val_main_output_loss: 2.0599 - val_aux_output_loss: 1.3053\n",
      "Epoch 252/500\n",
      " - 0s - loss: 10.0865 - main_output_loss: 9.4829 - aux_output_loss: 0.7540 - val_loss: 2.7408 - val_main_output_loss: 2.0288 - val_aux_output_loss: 1.2810\n",
      "Epoch 253/500\n",
      " - 0s - loss: 9.5166 - main_output_loss: 8.9147 - aux_output_loss: 0.7580 - val_loss: 2.7882 - val_main_output_loss: 2.0862 - val_aux_output_loss: 1.2585\n",
      "Epoch 254/500\n",
      " - 0s - loss: 9.4733 - main_output_loss: 8.8770 - aux_output_loss: 0.7458 - val_loss: 2.7294 - val_main_output_loss: 2.0285 - val_aux_output_loss: 1.2809\n",
      "Epoch 255/500\n",
      " - 0s - loss: 9.6807 - main_output_loss: 9.0904 - aux_output_loss: 0.7324 - val_loss: 2.7280 - val_main_output_loss: 2.0270 - val_aux_output_loss: 1.2701\n",
      "Epoch 256/500\n",
      " - 0s - loss: 9.5478 - main_output_loss: 8.9577 - aux_output_loss: 0.7341 - val_loss: 2.5702 - val_main_output_loss: 1.8643 - val_aux_output_loss: 1.3069\n",
      "Epoch 257/500\n",
      " - 0s - loss: 9.7105 - main_output_loss: 9.1186 - aux_output_loss: 0.7497 - val_loss: 2.9008 - val_main_output_loss: 2.2151 - val_aux_output_loss: 1.2111\n",
      "Epoch 258/500\n",
      " - 0s - loss: 9.7479 - main_output_loss: 9.1623 - aux_output_loss: 0.7320 - val_loss: 2.7322 - val_main_output_loss: 2.0436 - val_aux_output_loss: 1.2473\n",
      "Epoch 259/500\n",
      " - 0s - loss: 9.6140 - main_output_loss: 9.0305 - aux_output_loss: 0.7368 - val_loss: 2.7331 - val_main_output_loss: 2.0502 - val_aux_output_loss: 1.2222\n",
      "Epoch 260/500\n",
      " - 0s - loss: 9.5363 - main_output_loss: 8.9570 - aux_output_loss: 0.7166 - val_loss: 2.8377 - val_main_output_loss: 2.1606 - val_aux_output_loss: 1.1988\n",
      "Epoch 261/500\n",
      " - 0s - loss: 9.6391 - main_output_loss: 9.0608 - aux_output_loss: 0.7243 - val_loss: 2.8836 - val_main_output_loss: 2.2144 - val_aux_output_loss: 1.1750\n",
      "Epoch 262/500\n",
      " - 0s - loss: 9.5598 - main_output_loss: 8.9885 - aux_output_loss: 0.7057 - val_loss: 3.1942 - val_main_output_loss: 2.5397 - val_aux_output_loss: 1.1053\n",
      "Epoch 263/500\n",
      " - 0s - loss: 9.5205 - main_output_loss: 8.9520 - aux_output_loss: 0.6940 - val_loss: 2.8577 - val_main_output_loss: 2.1912 - val_aux_output_loss: 1.1727\n",
      "Epoch 264/500\n",
      " - 0s - loss: 9.3463 - main_output_loss: 8.7772 - aux_output_loss: 0.7054 - val_loss: 2.7997 - val_main_output_loss: 2.1353 - val_aux_output_loss: 1.1735\n",
      "Epoch 265/500\n",
      " - 0s - loss: 9.4531 - main_output_loss: 8.8841 - aux_output_loss: 0.7215 - val_loss: 2.8575 - val_main_output_loss: 2.2029 - val_aux_output_loss: 1.1543\n",
      "Epoch 266/500\n",
      " - 0s - loss: 9.6208 - main_output_loss: 9.0530 - aux_output_loss: 0.7184 - val_loss: 3.1555 - val_main_output_loss: 2.5203 - val_aux_output_loss: 1.0419\n",
      "Epoch 267/500\n",
      " - 0s - loss: 9.2659 - main_output_loss: 8.7053 - aux_output_loss: 0.6896 - val_loss: 2.8121 - val_main_output_loss: 2.1652 - val_aux_output_loss: 1.1208\n",
      "Epoch 268/500\n",
      " - 0s - loss: 9.4775 - main_output_loss: 8.9170 - aux_output_loss: 0.7034 - val_loss: 2.5432 - val_main_output_loss: 1.8900 - val_aux_output_loss: 1.1656\n",
      "Epoch 269/500\n",
      " - 0s - loss: 9.3313 - main_output_loss: 8.7756 - aux_output_loss: 0.6796 - val_loss: 2.5155 - val_main_output_loss: 1.8605 - val_aux_output_loss: 1.1838\n",
      "Epoch 270/500\n",
      " - 0s - loss: 9.5203 - main_output_loss: 8.9648 - aux_output_loss: 0.6911 - val_loss: 2.8187 - val_main_output_loss: 2.1821 - val_aux_output_loss: 1.0803\n",
      "Epoch 271/500\n",
      " - 0s - loss: 9.3877 - main_output_loss: 8.8380 - aux_output_loss: 0.6667 - val_loss: 2.8189 - val_main_output_loss: 2.1894 - val_aux_output_loss: 1.0757\n",
      "Epoch 272/500\n",
      " - 0s - loss: 9.2911 - main_output_loss: 8.7435 - aux_output_loss: 0.6664 - val_loss: 2.7123 - val_main_output_loss: 2.0808 - val_aux_output_loss: 1.0774\n",
      "Epoch 273/500\n",
      " - 0s - loss: 9.2165 - main_output_loss: 8.6688 - aux_output_loss: 0.6727 - val_loss: 2.8637 - val_main_output_loss: 2.2483 - val_aux_output_loss: 1.0020\n",
      "Epoch 274/500\n",
      " - 0s - loss: 8.9478 - main_output_loss: 8.4044 - aux_output_loss: 0.6597 - val_loss: 2.5648 - val_main_output_loss: 1.9316 - val_aux_output_loss: 1.0994\n",
      "Epoch 275/500\n",
      " - 0s - loss: 9.5323 - main_output_loss: 8.9877 - aux_output_loss: 0.6769 - val_loss: 2.7077 - val_main_output_loss: 2.0780 - val_aux_output_loss: 1.0989\n",
      "Epoch 276/500\n",
      " - 0s - loss: 9.2161 - main_output_loss: 8.6679 - aux_output_loss: 0.7008 - val_loss: 2.5643 - val_main_output_loss: 1.9325 - val_aux_output_loss: 1.1082\n",
      "Epoch 277/500\n",
      " - 0s - loss: 9.3911 - main_output_loss: 8.8484 - aux_output_loss: 0.6813 - val_loss: 2.6033 - val_main_output_loss: 1.9842 - val_aux_output_loss: 1.0464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/500\n",
      " - 0s - loss: 9.2549 - main_output_loss: 8.7203 - aux_output_loss: 0.6559 - val_loss: 2.6297 - val_main_output_loss: 2.0216 - val_aux_output_loss: 1.0338\n",
      "Epoch 279/500\n",
      " - 0s - loss: 9.2213 - main_output_loss: 8.6843 - aux_output_loss: 0.6714 - val_loss: 2.7153 - val_main_output_loss: 2.1128 - val_aux_output_loss: 0.9784\n",
      "Epoch 280/500\n",
      " - 0s - loss: 9.1678 - main_output_loss: 8.6311 - aux_output_loss: 0.6492 - val_loss: 2.6580 - val_main_output_loss: 2.0594 - val_aux_output_loss: 0.9567\n",
      "Epoch 281/500\n",
      " - 0s - loss: 9.3012 - main_output_loss: 8.7699 - aux_output_loss: 0.6380 - val_loss: 2.6930 - val_main_output_loss: 2.0960 - val_aux_output_loss: 0.9748\n",
      "Epoch 282/500\n",
      " - 0s - loss: 9.0294 - main_output_loss: 8.4957 - aux_output_loss: 0.6526 - val_loss: 2.5488 - val_main_output_loss: 1.9433 - val_aux_output_loss: 1.0047\n",
      "Epoch 283/500\n",
      " - 0s - loss: 8.9621 - main_output_loss: 8.4304 - aux_output_loss: 0.6544 - val_loss: 2.7022 - val_main_output_loss: 2.1051 - val_aux_output_loss: 0.9684\n",
      "Epoch 284/500\n",
      " - 0s - loss: 9.1811 - main_output_loss: 8.6502 - aux_output_loss: 0.6563 - val_loss: 2.6639 - val_main_output_loss: 2.0715 - val_aux_output_loss: 0.9531\n",
      "Epoch 285/500\n",
      " - 0s - loss: 9.0493 - main_output_loss: 8.5244 - aux_output_loss: 0.6371 - val_loss: 2.7877 - val_main_output_loss: 2.2055 - val_aux_output_loss: 0.9138\n",
      "Epoch 286/500\n",
      " - 0s - loss: 9.0358 - main_output_loss: 8.5100 - aux_output_loss: 0.6419 - val_loss: 2.7723 - val_main_output_loss: 2.1875 - val_aux_output_loss: 0.9272\n",
      "Epoch 287/500\n",
      " - 0s - loss: 8.9174 - main_output_loss: 8.3906 - aux_output_loss: 0.6446 - val_loss: 2.4197 - val_main_output_loss: 1.8201 - val_aux_output_loss: 1.0115\n",
      "Epoch 288/500\n",
      " - 0s - loss: 9.0641 - main_output_loss: 8.5396 - aux_output_loss: 0.6508 - val_loss: 2.6619 - val_main_output_loss: 2.0777 - val_aux_output_loss: 0.9513\n",
      "Epoch 289/500\n",
      " - 0s - loss: 8.8673 - main_output_loss: 8.3518 - aux_output_loss: 0.6310 - val_loss: 2.7731 - val_main_output_loss: 2.2050 - val_aux_output_loss: 0.8840\n",
      "Epoch 290/500\n",
      " - 0s - loss: 8.9057 - main_output_loss: 8.3837 - aux_output_loss: 0.6620 - val_loss: 2.7249 - val_main_output_loss: 2.1591 - val_aux_output_loss: 0.8709\n",
      "Epoch 291/500\n",
      " - 0s - loss: 8.6642 - main_output_loss: 8.1488 - aux_output_loss: 0.6249 - val_loss: 2.5603 - val_main_output_loss: 1.9914 - val_aux_output_loss: 0.8897\n",
      "Epoch 292/500\n",
      " - 0s - loss: 8.9206 - main_output_loss: 8.4100 - aux_output_loss: 0.6216 - val_loss: 2.7142 - val_main_output_loss: 2.1589 - val_aux_output_loss: 0.8480\n",
      "Epoch 293/500\n",
      " - 0s - loss: 8.7615 - main_output_loss: 8.2539 - aux_output_loss: 0.6053 - val_loss: 2.5194 - val_main_output_loss: 1.9485 - val_aux_output_loss: 0.9248\n",
      "Epoch 294/500\n",
      " - 0s - loss: 9.1017 - main_output_loss: 8.5899 - aux_output_loss: 0.6418 - val_loss: 2.6488 - val_main_output_loss: 2.0902 - val_aux_output_loss: 0.8779\n",
      "Epoch 295/500\n",
      " - 0s - loss: 8.7052 - main_output_loss: 8.2003 - aux_output_loss: 0.6186 - val_loss: 2.5277 - val_main_output_loss: 1.9662 - val_aux_output_loss: 0.8850\n",
      "Epoch 296/500\n",
      " - 0s - loss: 8.6994 - main_output_loss: 8.1932 - aux_output_loss: 0.6146 - val_loss: 2.5643 - val_main_output_loss: 2.0032 - val_aux_output_loss: 0.8796\n",
      "Epoch 297/500\n",
      " - 0s - loss: 9.0569 - main_output_loss: 8.5493 - aux_output_loss: 0.6316 - val_loss: 2.5032 - val_main_output_loss: 1.9440 - val_aux_output_loss: 0.8906\n",
      "Epoch 298/500\n",
      " - 0s - loss: 8.6168 - main_output_loss: 8.1130 - aux_output_loss: 0.6217 - val_loss: 2.5712 - val_main_output_loss: 2.0204 - val_aux_output_loss: 0.8490\n",
      "Epoch 299/500\n",
      " - 0s - loss: 8.6953 - main_output_loss: 8.1942 - aux_output_loss: 0.6182 - val_loss: 2.6733 - val_main_output_loss: 2.1259 - val_aux_output_loss: 0.8464\n",
      "Epoch 300/500\n",
      " - 0s - loss: 8.8201 - main_output_loss: 8.3180 - aux_output_loss: 0.6299 - val_loss: 2.5135 - val_main_output_loss: 1.9637 - val_aux_output_loss: 0.8563\n",
      "Epoch 301/500\n",
      " - 0s - loss: 8.6392 - main_output_loss: 8.1424 - aux_output_loss: 0.6081 - val_loss: 2.5765 - val_main_output_loss: 2.0320 - val_aux_output_loss: 0.8378\n",
      "Epoch 302/500\n",
      " - 0s - loss: 8.8220 - main_output_loss: 8.3226 - aux_output_loss: 0.6309 - val_loss: 2.8007 - val_main_output_loss: 2.2810 - val_aux_output_loss: 0.7254\n",
      "Epoch 303/500\n",
      " - 0s - loss: 8.4852 - main_output_loss: 7.9929 - aux_output_loss: 0.6011 - val_loss: 2.4764 - val_main_output_loss: 1.9377 - val_aux_output_loss: 0.8446\n",
      "Epoch 304/500\n",
      " - 0s - loss: 8.6244 - main_output_loss: 8.1316 - aux_output_loss: 0.6214 - val_loss: 2.5565 - val_main_output_loss: 2.0279 - val_aux_output_loss: 0.7837\n",
      "Epoch 305/500\n",
      " - 0s - loss: 8.8110 - main_output_loss: 8.3122 - aux_output_loss: 0.6392 - val_loss: 2.2636 - val_main_output_loss: 1.7060 - val_aux_output_loss: 0.9250\n",
      "Epoch 306/500\n",
      " - 0s - loss: 8.6714 - main_output_loss: 8.1739 - aux_output_loss: 0.6415 - val_loss: 2.6635 - val_main_output_loss: 2.1464 - val_aux_output_loss: 0.7501\n",
      "Epoch 307/500\n",
      " - 0s - loss: 8.5678 - main_output_loss: 8.0767 - aux_output_loss: 0.6166 - val_loss: 2.5270 - val_main_output_loss: 2.0005 - val_aux_output_loss: 0.7722\n",
      "Epoch 308/500\n",
      " - 0s - loss: 8.4261 - main_output_loss: 7.9355 - aux_output_loss: 0.6095 - val_loss: 2.5063 - val_main_output_loss: 1.9815 - val_aux_output_loss: 0.7666\n",
      "Epoch 309/500\n",
      " - 0s - loss: 8.5351 - main_output_loss: 8.0414 - aux_output_loss: 0.6278 - val_loss: 2.6376 - val_main_output_loss: 2.1255 - val_aux_output_loss: 0.7077\n",
      "Epoch 310/500\n",
      " - 0s - loss: 8.4617 - main_output_loss: 7.9706 - aux_output_loss: 0.6206 - val_loss: 2.3163 - val_main_output_loss: 1.7919 - val_aux_output_loss: 0.7886\n",
      "Epoch 311/500\n",
      " - 0s - loss: 8.4892 - main_output_loss: 7.9985 - aux_output_loss: 0.6148 - val_loss: 2.4137 - val_main_output_loss: 1.8957 - val_aux_output_loss: 0.7445\n",
      "Epoch 312/500\n",
      " - 0s - loss: 8.4180 - main_output_loss: 7.9328 - aux_output_loss: 0.6020 - val_loss: 2.4656 - val_main_output_loss: 1.9544 - val_aux_output_loss: 0.7430\n",
      "Epoch 313/500\n",
      " - 0s - loss: 8.5280 - main_output_loss: 8.0461 - aux_output_loss: 0.5978 - val_loss: 2.7326 - val_main_output_loss: 2.2460 - val_aux_output_loss: 0.6168\n",
      "Epoch 314/500\n",
      " - 0s - loss: 8.3101 - main_output_loss: 7.8279 - aux_output_loss: 0.5955 - val_loss: 2.5097 - val_main_output_loss: 2.0048 - val_aux_output_loss: 0.7029\n",
      "Epoch 315/500\n",
      " - 0s - loss: 8.3243 - main_output_loss: 7.8401 - aux_output_loss: 0.6241 - val_loss: 2.7114 - val_main_output_loss: 2.2301 - val_aux_output_loss: 0.6120\n",
      "Epoch 316/500\n",
      " - 1s - loss: 8.2130 - main_output_loss: 7.7350 - aux_output_loss: 0.5957 - val_loss: 2.4834 - val_main_output_loss: 1.9837 - val_aux_output_loss: 0.6896\n",
      "Epoch 317/500\n",
      " - 0s - loss: 8.3321 - main_output_loss: 7.8426 - aux_output_loss: 0.6510 - val_loss: 2.2286 - val_main_output_loss: 1.7186 - val_aux_output_loss: 0.7475\n",
      "Epoch 318/500\n",
      " - 0s - loss: 8.4291 - main_output_loss: 7.9444 - aux_output_loss: 0.6365 - val_loss: 2.4598 - val_main_output_loss: 1.9765 - val_aux_output_loss: 0.6412\n",
      "Epoch 319/500\n",
      " - 0s - loss: 8.2479 - main_output_loss: 7.7735 - aux_output_loss: 0.6149 - val_loss: 2.3606 - val_main_output_loss: 1.8677 - val_aux_output_loss: 0.6874\n",
      "Epoch 320/500\n",
      " - 0s - loss: 8.2964 - main_output_loss: 7.8169 - aux_output_loss: 0.6277 - val_loss: 2.6500 - val_main_output_loss: 2.1749 - val_aux_output_loss: 0.5981\n",
      "Epoch 321/500\n",
      " - 0s - loss: 8.2858 - main_output_loss: 7.8054 - aux_output_loss: 0.6197 - val_loss: 2.3724 - val_main_output_loss: 1.8738 - val_aux_output_loss: 0.6964\n",
      "Epoch 322/500\n",
      " - 1s - loss: 8.2141 - main_output_loss: 7.7305 - aux_output_loss: 0.6279 - val_loss: 2.3695 - val_main_output_loss: 1.8799 - val_aux_output_loss: 0.6660\n",
      "Epoch 323/500\n",
      " - 0s - loss: 47.7813 - main_output_loss: 44.8900 - aux_output_loss: 12.6658 - val_loss: 2.4977 - val_main_output_loss: 2.0101 - val_aux_output_loss: 0.6446\n",
      "Epoch 324/500\n",
      " - 0s - loss: 8.4107 - main_output_loss: 7.9244 - aux_output_loss: 0.6584 - val_loss: 2.5540 - val_main_output_loss: 2.0823 - val_aux_output_loss: 0.5790\n",
      "Epoch 325/500\n",
      " - 0s - loss: 8.1223 - main_output_loss: 7.6481 - aux_output_loss: 0.6056 - val_loss: 2.5367 - val_main_output_loss: 2.0601 - val_aux_output_loss: 0.6103\n",
      "Epoch 326/500\n",
      " - 0s - loss: 8.2396 - main_output_loss: 7.7616 - aux_output_loss: 0.6210 - val_loss: 2.4252 - val_main_output_loss: 1.9482 - val_aux_output_loss: 0.6116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/500\n",
      " - 0s - loss: 8.1580 - main_output_loss: 7.6840 - aux_output_loss: 0.6204 - val_loss: 2.3344 - val_main_output_loss: 1.8624 - val_aux_output_loss: 0.6096\n",
      "Epoch 328/500\n",
      " - 0s - loss: 8.1254 - main_output_loss: 7.6451 - aux_output_loss: 0.6493 - val_loss: 2.3864 - val_main_output_loss: 1.9159 - val_aux_output_loss: 0.5981\n",
      "Epoch 329/500\n",
      " - 0s - loss: 8.1863 - main_output_loss: 7.7114 - aux_output_loss: 0.6318 - val_loss: 2.4529 - val_main_output_loss: 1.9827 - val_aux_output_loss: 0.5930\n",
      "Epoch 330/500\n",
      " - 0s - loss: 8.1464 - main_output_loss: 7.6716 - aux_output_loss: 0.6310 - val_loss: 2.5603 - val_main_output_loss: 2.1038 - val_aux_output_loss: 0.5249\n",
      "Epoch 331/500\n",
      " - 0s - loss: 8.2631 - main_output_loss: 7.7963 - aux_output_loss: 0.5915 - val_loss: 2.3867 - val_main_output_loss: 1.9191 - val_aux_output_loss: 0.5980\n",
      "Epoch 332/500\n",
      " - 0s - loss: 8.1558 - main_output_loss: 7.6815 - aux_output_loss: 0.6232 - val_loss: 2.3896 - val_main_output_loss: 1.9147 - val_aux_output_loss: 0.6166\n",
      "Epoch 333/500\n",
      " - 0s - loss: 7.8578 - main_output_loss: 7.3765 - aux_output_loss: 0.6645 - val_loss: 2.5006 - val_main_output_loss: 2.0445 - val_aux_output_loss: 0.5314\n",
      "Epoch 334/500\n",
      " - 0s - loss: 8.1064 - main_output_loss: 7.6361 - aux_output_loss: 0.6262 - val_loss: 2.0977 - val_main_output_loss: 1.6222 - val_aux_output_loss: 0.6505\n",
      "Epoch 335/500\n",
      " - 0s - loss: 8.0852 - main_output_loss: 7.6150 - aux_output_loss: 0.6428 - val_loss: 2.4187 - val_main_output_loss: 1.9695 - val_aux_output_loss: 0.5341\n",
      "Epoch 336/500\n",
      " - 0s - loss: 8.1189 - main_output_loss: 7.6460 - aux_output_loss: 0.6535 - val_loss: 2.3552 - val_main_output_loss: 1.9028 - val_aux_output_loss: 0.5439\n",
      "Epoch 337/500\n",
      " - 0s - loss: 8.0466 - main_output_loss: 7.5750 - aux_output_loss: 0.6557 - val_loss: 2.5428 - val_main_output_loss: 2.1021 - val_aux_output_loss: 0.4946\n",
      "Epoch 338/500\n",
      " - 0s - loss: 7.8187 - main_output_loss: 7.3521 - aux_output_loss: 0.6416 - val_loss: 2.2375 - val_main_output_loss: 1.7759 - val_aux_output_loss: 0.6108\n",
      "Epoch 339/500\n",
      " - 0s - loss: 7.9610 - main_output_loss: 7.4969 - aux_output_loss: 0.6369 - val_loss: 2.3564 - val_main_output_loss: 1.9129 - val_aux_output_loss: 0.5258\n",
      "Epoch 340/500\n",
      " - 0s - loss: 7.9041 - main_output_loss: 7.4307 - aux_output_loss: 0.6796 - val_loss: 2.4291 - val_main_output_loss: 1.9806 - val_aux_output_loss: 0.5306\n",
      "Epoch 341/500\n",
      " - 0s - loss: 7.9409 - main_output_loss: 7.4741 - aux_output_loss: 0.6359 - val_loss: 2.5654 - val_main_output_loss: 2.1279 - val_aux_output_loss: 0.4847\n",
      "Epoch 342/500\n",
      " - 0s - loss: 7.9259 - main_output_loss: 7.4582 - aux_output_loss: 0.6391 - val_loss: 2.3709 - val_main_output_loss: 1.9261 - val_aux_output_loss: 0.5188\n",
      "Epoch 343/500\n",
      " - 0s - loss: 7.8838 - main_output_loss: 7.4052 - aux_output_loss: 0.6963 - val_loss: 2.3443 - val_main_output_loss: 1.8945 - val_aux_output_loss: 0.5339\n",
      "Epoch 344/500\n",
      " - 0s - loss: 8.0998 - main_output_loss: 7.6285 - aux_output_loss: 0.6581 - val_loss: 2.3894 - val_main_output_loss: 1.9463 - val_aux_output_loss: 0.5097\n",
      "Epoch 345/500\n",
      " - 0s - loss: 8.0061 - main_output_loss: 7.5420 - aux_output_loss: 0.6271 - val_loss: 2.3097 - val_main_output_loss: 1.8682 - val_aux_output_loss: 0.5091\n",
      "Epoch 346/500\n",
      " - 0s - loss: 7.9524 - main_output_loss: 7.4820 - aux_output_loss: 0.6590 - val_loss: 2.4559 - val_main_output_loss: 2.0257 - val_aux_output_loss: 0.4554\n",
      "Epoch 347/500\n",
      " - 0s - loss: 8.1046 - main_output_loss: 7.6417 - aux_output_loss: 0.6261 - val_loss: 2.3652 - val_main_output_loss: 1.9290 - val_aux_output_loss: 0.5110\n",
      "Epoch 348/500\n",
      " - 0s - loss: 7.6839 - main_output_loss: 7.2294 - aux_output_loss: 0.6118 - val_loss: 2.5394 - val_main_output_loss: 2.1138 - val_aux_output_loss: 0.4498\n",
      "Epoch 349/500\n",
      " - 0s - loss: 7.9251 - main_output_loss: 7.4592 - aux_output_loss: 0.6515 - val_loss: 2.4752 - val_main_output_loss: 2.0472 - val_aux_output_loss: 0.4747\n",
      "Epoch 350/500\n",
      " - 0s - loss: 7.7111 - main_output_loss: 7.2445 - aux_output_loss: 0.6714 - val_loss: 2.2235 - val_main_output_loss: 1.7882 - val_aux_output_loss: 0.4966\n",
      "Epoch 351/500\n",
      " - 0s - loss: 7.6578 - main_output_loss: 7.1904 - aux_output_loss: 0.6673 - val_loss: 2.1032 - val_main_output_loss: 1.6517 - val_aux_output_loss: 0.5756\n",
      "Epoch 352/500\n",
      " - 0s - loss: 7.5721 - main_output_loss: 7.1107 - aux_output_loss: 0.6432 - val_loss: 2.1145 - val_main_output_loss: 1.6664 - val_aux_output_loss: 0.5579\n",
      "Epoch 353/500\n",
      " - 0s - loss: 7.7992 - main_output_loss: 7.3296 - aux_output_loss: 0.6886 - val_loss: 2.3554 - val_main_output_loss: 1.9312 - val_aux_output_loss: 0.4517\n",
      "Epoch 354/500\n",
      " - 0s - loss: 7.8420 - main_output_loss: 7.3803 - aux_output_loss: 0.6487 - val_loss: 2.3686 - val_main_output_loss: 1.9440 - val_aux_output_loss: 0.4522\n",
      "Epoch 355/500\n",
      " - 0s - loss: 7.7103 - main_output_loss: 7.2422 - aux_output_loss: 0.6764 - val_loss: 2.4001 - val_main_output_loss: 1.9800 - val_aux_output_loss: 0.4361\n",
      "Epoch 356/500\n",
      " - 0s - loss: 7.7783 - main_output_loss: 7.3201 - aux_output_loss: 0.6379 - val_loss: 2.3557 - val_main_output_loss: 1.9312 - val_aux_output_loss: 0.4508\n",
      "Epoch 357/500\n",
      " - 0s - loss: 7.3920 - main_output_loss: 6.9247 - aux_output_loss: 0.6661 - val_loss: 2.3054 - val_main_output_loss: 1.8744 - val_aux_output_loss: 0.4855\n",
      "Epoch 358/500\n",
      " - 0s - loss: 7.6053 - main_output_loss: 7.1445 - aux_output_loss: 0.6357 - val_loss: 2.3973 - val_main_output_loss: 1.9788 - val_aux_output_loss: 0.4199\n",
      "Epoch 359/500\n",
      " - 1s - loss: 7.2555 - main_output_loss: 6.7933 - aux_output_loss: 0.6399 - val_loss: 2.2180 - val_main_output_loss: 1.7905 - val_aux_output_loss: 0.4726\n",
      "Epoch 360/500\n",
      " - 1s - loss: 7.5408 - main_output_loss: 7.0815 - aux_output_loss: 0.6471 - val_loss: 2.1749 - val_main_output_loss: 1.7433 - val_aux_output_loss: 0.4909\n",
      "Epoch 361/500\n",
      " - 0s - loss: 7.6953 - main_output_loss: 7.2294 - aux_output_loss: 0.6637 - val_loss: 2.2655 - val_main_output_loss: 1.8305 - val_aux_output_loss: 0.4865\n",
      "Epoch 362/500\n",
      " - 0s - loss: 7.6278 - main_output_loss: 7.1654 - aux_output_loss: 0.6406 - val_loss: 2.3598 - val_main_output_loss: 1.9286 - val_aux_output_loss: 0.4805\n",
      "Epoch 363/500\n",
      " - 0s - loss: 7.7617 - main_output_loss: 7.2985 - aux_output_loss: 0.6543 - val_loss: 2.2384 - val_main_output_loss: 1.8060 - val_aux_output_loss: 0.4968\n",
      "Epoch 364/500\n",
      " - 0s - loss: 7.4357 - main_output_loss: 6.9725 - aux_output_loss: 0.6670 - val_loss: 2.3856 - val_main_output_loss: 1.9659 - val_aux_output_loss: 0.4451\n",
      "Epoch 365/500\n",
      " - 0s - loss: 7.3703 - main_output_loss: 6.9077 - aux_output_loss: 0.6740 - val_loss: 2.3251 - val_main_output_loss: 1.9072 - val_aux_output_loss: 0.4471\n",
      "Epoch 366/500\n",
      " - 0s - loss: 7.4859 - main_output_loss: 7.0083 - aux_output_loss: 0.7458 - val_loss: 2.2006 - val_main_output_loss: 1.7745 - val_aux_output_loss: 0.4776\n",
      "Epoch 367/500\n",
      " - 0s - loss: 7.6206 - main_output_loss: 7.1604 - aux_output_loss: 0.6518 - val_loss: 2.2067 - val_main_output_loss: 1.7860 - val_aux_output_loss: 0.4664\n",
      "Epoch 368/500\n",
      " - 0s - loss: 7.3061 - main_output_loss: 6.8516 - aux_output_loss: 0.6499 - val_loss: 2.2957 - val_main_output_loss: 1.8791 - val_aux_output_loss: 0.4418\n",
      "Epoch 369/500\n",
      " - 0s - loss: 7.2840 - main_output_loss: 6.8213 - aux_output_loss: 0.6718 - val_loss: 2.3714 - val_main_output_loss: 1.9659 - val_aux_output_loss: 0.3705\n",
      "Epoch 370/500\n",
      " - 0s - loss: 7.3518 - main_output_loss: 6.8984 - aux_output_loss: 0.6216 - val_loss: 2.2158 - val_main_output_loss: 1.7948 - val_aux_output_loss: 0.4613\n",
      "Epoch 371/500\n",
      " - 0s - loss: 7.3509 - main_output_loss: 6.8958 - aux_output_loss: 0.6368 - val_loss: 2.1678 - val_main_output_loss: 1.7458 - val_aux_output_loss: 0.4641\n",
      "Epoch 372/500\n",
      " - 0s - loss: 7.2429 - main_output_loss: 6.7786 - aux_output_loss: 0.6817 - val_loss: 2.4221 - val_main_output_loss: 2.0212 - val_aux_output_loss: 0.3613\n",
      "Epoch 373/500\n",
      " - 0s - loss: 7.4900 - main_output_loss: 7.0367 - aux_output_loss: 0.6322 - val_loss: 2.0057 - val_main_output_loss: 1.5786 - val_aux_output_loss: 0.4850\n",
      "Epoch 374/500\n",
      " - 0s - loss: 7.5412 - main_output_loss: 7.0843 - aux_output_loss: 0.6487 - val_loss: 2.1944 - val_main_output_loss: 1.7821 - val_aux_output_loss: 0.4162\n",
      "Epoch 375/500\n",
      " - 0s - loss: 7.2473 - main_output_loss: 6.7931 - aux_output_loss: 0.6406 - val_loss: 2.3532 - val_main_output_loss: 1.9538 - val_aux_output_loss: 0.3644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/500\n",
      " - 0s - loss: 7.3544 - main_output_loss: 6.9072 - aux_output_loss: 0.6119 - val_loss: 2.2931 - val_main_output_loss: 1.8929 - val_aux_output_loss: 0.3775\n",
      "Epoch 377/500\n",
      " - 0s - loss: 7.3474 - main_output_loss: 6.8916 - aux_output_loss: 0.6585 - val_loss: 2.1736 - val_main_output_loss: 1.7587 - val_aux_output_loss: 0.4483\n",
      "Epoch 378/500\n",
      " - 0s - loss: 7.0921 - main_output_loss: 6.6364 - aux_output_loss: 0.6567 - val_loss: 2.2537 - val_main_output_loss: 1.8469 - val_aux_output_loss: 0.3927\n",
      "Epoch 379/500\n",
      " - 0s - loss: 7.3868 - main_output_loss: 6.9323 - aux_output_loss: 0.6534 - val_loss: 2.2123 - val_main_output_loss: 1.8072 - val_aux_output_loss: 0.3923\n",
      "Epoch 380/500\n",
      " - 0s - loss: 7.3663 - main_output_loss: 6.9138 - aux_output_loss: 0.6381 - val_loss: 2.2604 - val_main_output_loss: 1.8581 - val_aux_output_loss: 0.3653\n",
      "Epoch 381/500\n",
      " - 0s - loss: 7.2359 - main_output_loss: 6.7806 - aux_output_loss: 0.6461 - val_loss: 2.4040 - val_main_output_loss: 2.0120 - val_aux_output_loss: 0.3294\n",
      "Epoch 382/500\n",
      " - 0s - loss: 7.2450 - main_output_loss: 6.7806 - aux_output_loss: 0.6971 - val_loss: 2.0680 - val_main_output_loss: 1.6526 - val_aux_output_loss: 0.4434\n",
      "Epoch 383/500\n",
      " - 0s - loss: 7.3509 - main_output_loss: 6.8969 - aux_output_loss: 0.6416 - val_loss: 2.1782 - val_main_output_loss: 1.7730 - val_aux_output_loss: 0.3878\n",
      "Epoch 384/500\n",
      " - 0s - loss: 7.3009 - main_output_loss: 6.8505 - aux_output_loss: 0.6264 - val_loss: 2.1751 - val_main_output_loss: 1.7728 - val_aux_output_loss: 0.3689\n",
      "Epoch 385/500\n",
      " - 0s - loss: 7.1505 - main_output_loss: 6.7005 - aux_output_loss: 0.6251 - val_loss: 2.1434 - val_main_output_loss: 1.7271 - val_aux_output_loss: 0.4350\n",
      "Epoch 386/500\n",
      " - 0s - loss: 7.2339 - main_output_loss: 6.7719 - aux_output_loss: 0.6815 - val_loss: 2.2880 - val_main_output_loss: 1.8818 - val_aux_output_loss: 0.3993\n",
      "Epoch 387/500\n",
      " - 0s - loss: 7.2918 - main_output_loss: 6.8300 - aux_output_loss: 0.6815 - val_loss: 2.2070 - val_main_output_loss: 1.8032 - val_aux_output_loss: 0.3946\n",
      "Epoch 388/500\n",
      " - 0s - loss: 7.4104 - main_output_loss: 6.9586 - aux_output_loss: 0.6484 - val_loss: 2.2115 - val_main_output_loss: 1.8093 - val_aux_output_loss: 0.3862\n",
      "Epoch 389/500\n",
      " - 0s - loss: 7.1533 - main_output_loss: 6.6982 - aux_output_loss: 0.6580 - val_loss: 2.1689 - val_main_output_loss: 1.7694 - val_aux_output_loss: 0.3695\n",
      "Epoch 390/500\n",
      " - 0s - loss: 7.3587 - main_output_loss: 6.9054 - aux_output_loss: 0.6411 - val_loss: 2.0803 - val_main_output_loss: 1.6674 - val_aux_output_loss: 0.4372\n",
      "Epoch 391/500\n",
      " - 0s - loss: 7.0151 - main_output_loss: 6.5576 - aux_output_loss: 0.6645 - val_loss: 1.9879 - val_main_output_loss: 1.5711 - val_aux_output_loss: 0.4610\n",
      "Epoch 392/500\n",
      " - 0s - loss: 7.0785 - main_output_loss: 6.6251 - aux_output_loss: 0.6544 - val_loss: 2.0513 - val_main_output_loss: 1.6409 - val_aux_output_loss: 0.4331\n",
      "Epoch 393/500\n",
      " - 0s - loss: 6.8743 - main_output_loss: 6.4230 - aux_output_loss: 0.6521 - val_loss: 2.1993 - val_main_output_loss: 1.8032 - val_aux_output_loss: 0.3736\n",
      "Epoch 394/500\n",
      " - 0s - loss: 7.1461 - main_output_loss: 6.6944 - aux_output_loss: 0.6597 - val_loss: 2.3233 - val_main_output_loss: 1.9297 - val_aux_output_loss: 0.3490\n",
      "Epoch 395/500\n",
      " - 0s - loss: 7.3037 - main_output_loss: 6.8539 - aux_output_loss: 0.6432 - val_loss: 2.1520 - val_main_output_loss: 1.7530 - val_aux_output_loss: 0.3904\n",
      "Epoch 396/500\n",
      " - 0s - loss: 7.0860 - main_output_loss: 6.6315 - aux_output_loss: 0.6691 - val_loss: 2.2032 - val_main_output_loss: 1.8067 - val_aux_output_loss: 0.3813\n",
      "Epoch 397/500\n",
      " - 0s - loss: 7.0700 - main_output_loss: 6.6187 - aux_output_loss: 0.6504 - val_loss: 2.1483 - val_main_output_loss: 1.7489 - val_aux_output_loss: 0.3734\n",
      "Epoch 398/500\n",
      " - 0s - loss: 7.0120 - main_output_loss: 6.5585 - aux_output_loss: 0.6593 - val_loss: 2.2023 - val_main_output_loss: 1.8092 - val_aux_output_loss: 0.3584\n",
      "Epoch 399/500\n",
      " - 0s - loss: 7.0284 - main_output_loss: 6.5817 - aux_output_loss: 0.6339 - val_loss: 2.3224 - val_main_output_loss: 1.9379 - val_aux_output_loss: 0.3103\n",
      "Epoch 400/500\n",
      " - 0s - loss: 7.0419 - main_output_loss: 6.5994 - aux_output_loss: 0.6119 - val_loss: 2.0604 - val_main_output_loss: 1.6588 - val_aux_output_loss: 0.4044\n",
      "Epoch 401/500\n",
      " - 0s - loss: 6.8115 - main_output_loss: 6.3636 - aux_output_loss: 0.6440 - val_loss: 2.1585 - val_main_output_loss: 1.7609 - val_aux_output_loss: 0.3811\n",
      "Epoch 402/500\n",
      " - 0s - loss: 7.0739 - main_output_loss: 6.6269 - aux_output_loss: 0.6426 - val_loss: 2.2713 - val_main_output_loss: 1.8826 - val_aux_output_loss: 0.3511\n",
      "Epoch 403/500\n",
      " - 0s - loss: 6.9442 - main_output_loss: 6.4978 - aux_output_loss: 0.6452 - val_loss: 2.0455 - val_main_output_loss: 1.6402 - val_aux_output_loss: 0.4386\n",
      "Epoch 404/500\n",
      " - 0s - loss: 7.1714 - main_output_loss: 6.7273 - aux_output_loss: 0.6454 - val_loss: 2.1157 - val_main_output_loss: 1.7212 - val_aux_output_loss: 0.3856\n",
      "Epoch 405/500\n",
      " - 0s - loss: 7.0018 - main_output_loss: 6.5591 - aux_output_loss: 0.6330 - val_loss: 2.0423 - val_main_output_loss: 1.6383 - val_aux_output_loss: 0.4297\n",
      "Epoch 406/500\n",
      " - 0s - loss: 6.9947 - main_output_loss: 6.5496 - aux_output_loss: 0.6434 - val_loss: 2.2214 - val_main_output_loss: 1.8325 - val_aux_output_loss: 0.3541\n",
      "Epoch 407/500\n",
      " - 0s - loss: 6.9700 - main_output_loss: 6.5230 - aux_output_loss: 0.6527 - val_loss: 2.2580 - val_main_output_loss: 1.8681 - val_aux_output_loss: 0.3662\n",
      "Epoch 408/500\n",
      " - 0s - loss: 6.9098 - main_output_loss: 6.4544 - aux_output_loss: 0.6870 - val_loss: 2.1696 - val_main_output_loss: 1.7684 - val_aux_output_loss: 0.4008\n",
      "Epoch 409/500\n",
      " - 0s - loss: 6.7320 - main_output_loss: 6.2810 - aux_output_loss: 0.6717 - val_loss: 2.2118 - val_main_output_loss: 1.8155 - val_aux_output_loss: 0.3855\n",
      "Epoch 410/500\n",
      " - 0s - loss: 6.9181 - main_output_loss: 6.4633 - aux_output_loss: 0.6895 - val_loss: 2.1693 - val_main_output_loss: 1.7812 - val_aux_output_loss: 0.3570\n",
      "Epoch 411/500\n",
      " - 0s - loss: 6.8879 - main_output_loss: 6.4439 - aux_output_loss: 0.6389 - val_loss: 2.1772 - val_main_output_loss: 1.7912 - val_aux_output_loss: 0.3464\n",
      "Epoch 412/500\n",
      " - 0s - loss: 6.6999 - main_output_loss: 6.2513 - aux_output_loss: 0.6676 - val_loss: 1.9385 - val_main_output_loss: 1.5320 - val_aux_output_loss: 0.4591\n",
      "Epoch 413/500\n",
      " - 0s - loss: 6.9862 - main_output_loss: 6.5341 - aux_output_loss: 0.6931 - val_loss: 2.0884 - val_main_output_loss: 1.6951 - val_aux_output_loss: 0.3825\n",
      "Epoch 414/500\n",
      " - 0s - loss: 6.8847 - main_output_loss: 6.4378 - aux_output_loss: 0.6647 - val_loss: 2.1101 - val_main_output_loss: 1.7215 - val_aux_output_loss: 0.3813\n",
      "Epoch 415/500\n",
      " - 0s - loss: 6.7999 - main_output_loss: 6.3612 - aux_output_loss: 0.6323 - val_loss: 2.3541 - val_main_output_loss: 1.9826 - val_aux_output_loss: 0.2878\n",
      "Epoch 416/500\n",
      " - 0s - loss: 6.8334 - main_output_loss: 6.3925 - aux_output_loss: 0.6366 - val_loss: 2.0456 - val_main_output_loss: 1.6536 - val_aux_output_loss: 0.3770\n",
      "Epoch 417/500\n",
      " - 0s - loss: 6.9857 - main_output_loss: 6.5423 - aux_output_loss: 0.6392 - val_loss: 2.0702 - val_main_output_loss: 1.6815 - val_aux_output_loss: 0.3603\n",
      "Epoch 418/500\n",
      " - 0s - loss: 6.7976 - main_output_loss: 6.3557 - aux_output_loss: 0.6359 - val_loss: 2.1956 - val_main_output_loss: 1.8123 - val_aux_output_loss: 0.3406\n",
      "Epoch 419/500\n",
      " - 0s - loss: 6.6782 - main_output_loss: 6.2335 - aux_output_loss: 0.6679 - val_loss: 2.0636 - val_main_output_loss: 1.6691 - val_aux_output_loss: 0.4034\n",
      "Epoch 420/500\n",
      " - 0s - loss: 6.5412 - main_output_loss: 6.0983 - aux_output_loss: 0.6561 - val_loss: 2.1904 - val_main_output_loss: 1.8078 - val_aux_output_loss: 0.3477\n",
      "Epoch 421/500\n",
      " - 0s - loss: 6.9179 - main_output_loss: 6.4799 - aux_output_loss: 0.6366 - val_loss: 2.1448 - val_main_output_loss: 1.7616 - val_aux_output_loss: 0.3552\n",
      "Epoch 422/500\n",
      " - 0s - loss: 6.5977 - main_output_loss: 6.1549 - aux_output_loss: 0.6541 - val_loss: 1.9956 - val_main_output_loss: 1.6065 - val_aux_output_loss: 0.3728\n",
      "Epoch 423/500\n",
      " - 0s - loss: 6.6430 - main_output_loss: 6.2012 - aux_output_loss: 0.6523 - val_loss: 2.0459 - val_main_output_loss: 1.6628 - val_aux_output_loss: 0.3454\n",
      "Epoch 424/500\n",
      " - 0s - loss: 6.7090 - main_output_loss: 6.2638 - aux_output_loss: 0.6606 - val_loss: 2.2133 - val_main_output_loss: 1.8379 - val_aux_output_loss: 0.3062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/500\n",
      " - 0s - loss: 6.7345 - main_output_loss: 6.2956 - aux_output_loss: 0.6345 - val_loss: 2.3078 - val_main_output_loss: 1.9311 - val_aux_output_loss: 0.3075\n",
      "Epoch 426/500\n",
      " - 0s - loss: 6.7284 - main_output_loss: 6.2784 - aux_output_loss: 0.6698 - val_loss: 2.1924 - val_main_output_loss: 1.8069 - val_aux_output_loss: 0.3456\n",
      "Epoch 427/500\n",
      " - 0s - loss: 6.4987 - main_output_loss: 6.0482 - aux_output_loss: 0.6847 - val_loss: 2.1022 - val_main_output_loss: 1.7193 - val_aux_output_loss: 0.3526\n",
      "Epoch 428/500\n",
      " - 0s - loss: 6.7758 - main_output_loss: 6.3428 - aux_output_loss: 0.6105 - val_loss: 2.2564 - val_main_output_loss: 1.8811 - val_aux_output_loss: 0.3206\n",
      "Epoch 429/500\n",
      " - 0s - loss: 6.5738 - main_output_loss: 6.1389 - aux_output_loss: 0.6251 - val_loss: 2.0972 - val_main_output_loss: 1.7103 - val_aux_output_loss: 0.3717\n",
      "Epoch 430/500\n",
      " - 0s - loss: 6.6896 - main_output_loss: 6.2476 - aux_output_loss: 0.6584 - val_loss: 2.2198 - val_main_output_loss: 1.8443 - val_aux_output_loss: 0.3108\n",
      "Epoch 431/500\n",
      " - 0s - loss: 6.5112 - main_output_loss: 6.0697 - aux_output_loss: 0.6532 - val_loss: 2.1410 - val_main_output_loss: 1.7676 - val_aux_output_loss: 0.3100\n",
      "Epoch 432/500\n",
      " - 0s - loss: 6.7499 - main_output_loss: 6.3056 - aux_output_loss: 0.6704 - val_loss: 2.2128 - val_main_output_loss: 1.8375 - val_aux_output_loss: 0.3214\n",
      "Epoch 433/500\n",
      " - 0s - loss: 6.6141 - main_output_loss: 6.1722 - aux_output_loss: 0.6604 - val_loss: 2.0402 - val_main_output_loss: 1.6580 - val_aux_output_loss: 0.3536\n",
      "Epoch 434/500\n",
      " - 0s - loss: 6.5937 - main_output_loss: 6.1583 - aux_output_loss: 0.6407 - val_loss: 2.2676 - val_main_output_loss: 1.9011 - val_aux_output_loss: 0.2874\n",
      "Epoch 435/500\n",
      " - 0s - loss: 6.5689 - main_output_loss: 6.1260 - aux_output_loss: 0.6706 - val_loss: 2.1626 - val_main_output_loss: 1.7879 - val_aux_output_loss: 0.3227\n",
      "Epoch 436/500\n",
      " - 0s - loss: 6.5076 - main_output_loss: 6.0695 - aux_output_loss: 0.6454 - val_loss: 2.0435 - val_main_output_loss: 1.6684 - val_aux_output_loss: 0.3196\n",
      "Epoch 437/500\n",
      " - 0s - loss: 6.5811 - main_output_loss: 6.1433 - aux_output_loss: 0.6380 - val_loss: 2.1639 - val_main_output_loss: 1.7906 - val_aux_output_loss: 0.2990\n",
      "Epoch 438/500\n",
      " - 0s - loss: 6.4607 - main_output_loss: 6.0253 - aux_output_loss: 0.6299 - val_loss: 2.0584 - val_main_output_loss: 1.6814 - val_aux_output_loss: 0.3318\n",
      "Epoch 439/500\n",
      " - 0s - loss: 6.6027 - main_output_loss: 6.1567 - aux_output_loss: 0.6695 - val_loss: 2.0429 - val_main_output_loss: 1.6605 - val_aux_output_loss: 0.3466\n",
      "Epoch 440/500\n",
      " - 0s - loss: 6.4884 - main_output_loss: 6.0511 - aux_output_loss: 0.6306 - val_loss: 2.0571 - val_main_output_loss: 1.6783 - val_aux_output_loss: 0.3274\n",
      "Epoch 441/500\n",
      " - 0s - loss: 6.6320 - main_output_loss: 6.1930 - aux_output_loss: 0.6465 - val_loss: 2.1192 - val_main_output_loss: 1.7423 - val_aux_output_loss: 0.3290\n",
      "Epoch 442/500\n",
      " - 0s - loss: 6.5660 - main_output_loss: 6.1319 - aux_output_loss: 0.6258 - val_loss: 2.0018 - val_main_output_loss: 1.6195 - val_aux_output_loss: 0.3604\n",
      "Epoch 443/500\n",
      " - 0s - loss: 6.3744 - main_output_loss: 5.9394 - aux_output_loss: 0.6378 - val_loss: 2.2816 - val_main_output_loss: 1.9147 - val_aux_output_loss: 0.2867\n",
      "Epoch 444/500\n",
      " - 0s - loss: 6.3614 - main_output_loss: 5.9176 - aux_output_loss: 0.6725 - val_loss: 2.0644 - val_main_output_loss: 1.6852 - val_aux_output_loss: 0.3227\n",
      "Epoch 445/500\n",
      " - 0s - loss: 6.5249 - main_output_loss: 6.0878 - aux_output_loss: 0.6431 - val_loss: 2.1621 - val_main_output_loss: 1.7933 - val_aux_output_loss: 0.3022\n",
      "Epoch 446/500\n",
      " - 0s - loss: 6.3376 - main_output_loss: 5.9015 - aux_output_loss: 0.6497 - val_loss: 2.0674 - val_main_output_loss: 1.6958 - val_aux_output_loss: 0.3144\n",
      "Epoch 447/500\n",
      " - 0s - loss: 6.2234 - main_output_loss: 5.7864 - aux_output_loss: 0.6443 - val_loss: 2.1829 - val_main_output_loss: 1.8177 - val_aux_output_loss: 0.2825\n",
      "Epoch 448/500\n",
      " - 0s - loss: 6.3969 - main_output_loss: 5.9582 - aux_output_loss: 0.6637 - val_loss: 1.9224 - val_main_output_loss: 1.5412 - val_aux_output_loss: 0.3596\n",
      "Epoch 449/500\n",
      " - 0s - loss: 6.2141 - main_output_loss: 5.7817 - aux_output_loss: 0.6388 - val_loss: 2.1821 - val_main_output_loss: 1.8155 - val_aux_output_loss: 0.2954\n",
      "Epoch 450/500\n",
      " - 0s - loss: 6.3115 - main_output_loss: 5.8727 - aux_output_loss: 0.6518 - val_loss: 2.0840 - val_main_output_loss: 1.7116 - val_aux_output_loss: 0.3126\n",
      "Epoch 451/500\n",
      " - 0s - loss: 6.3061 - main_output_loss: 5.8654 - aux_output_loss: 0.6635 - val_loss: 2.3391 - val_main_output_loss: 1.9802 - val_aux_output_loss: 0.2492\n",
      "Epoch 452/500\n",
      " - 0s - loss: 6.2269 - main_output_loss: 5.7891 - aux_output_loss: 0.6461 - val_loss: 1.9783 - val_main_output_loss: 1.6025 - val_aux_output_loss: 0.3230\n",
      "Epoch 453/500\n",
      " - 0s - loss: 6.4487 - main_output_loss: 6.0143 - aux_output_loss: 0.6495 - val_loss: 2.0200 - val_main_output_loss: 1.6505 - val_aux_output_loss: 0.3226\n",
      "Epoch 454/500\n",
      " - 0s - loss: 6.3771 - main_output_loss: 5.9507 - aux_output_loss: 0.6107 - val_loss: 1.9179 - val_main_output_loss: 1.5390 - val_aux_output_loss: 0.3622\n",
      "Epoch 455/500\n",
      " - 0s - loss: 6.4216 - main_output_loss: 5.9922 - aux_output_loss: 0.6269 - val_loss: 2.1277 - val_main_output_loss: 1.7598 - val_aux_output_loss: 0.3043\n",
      "Epoch 456/500\n",
      " - 0s - loss: 6.4020 - main_output_loss: 5.9633 - aux_output_loss: 0.6571 - val_loss: 2.0239 - val_main_output_loss: 1.6501 - val_aux_output_loss: 0.3091\n",
      "Epoch 457/500\n",
      " - 0s - loss: 6.1854 - main_output_loss: 5.7542 - aux_output_loss: 0.6163 - val_loss: 2.0965 - val_main_output_loss: 1.7275 - val_aux_output_loss: 0.3029\n",
      "Epoch 458/500\n",
      " - 0s - loss: 6.2261 - main_output_loss: 5.7921 - aux_output_loss: 0.6395 - val_loss: 2.2080 - val_main_output_loss: 1.8457 - val_aux_output_loss: 0.2742\n",
      "Epoch 459/500\n",
      " - 0s - loss: 6.1889 - main_output_loss: 5.7537 - aux_output_loss: 0.6394 - val_loss: 2.0629 - val_main_output_loss: 1.6957 - val_aux_output_loss: 0.2988\n",
      "Epoch 460/500\n",
      " - 0s - loss: 6.1551 - main_output_loss: 5.7318 - aux_output_loss: 0.5954 - val_loss: 2.1837 - val_main_output_loss: 1.8250 - val_aux_output_loss: 0.2582\n",
      "Epoch 461/500\n",
      " - 0s - loss: 6.2613 - main_output_loss: 5.8312 - aux_output_loss: 0.6138 - val_loss: 2.1874 - val_main_output_loss: 1.8248 - val_aux_output_loss: 0.2706\n",
      "Epoch 462/500\n",
      " - 0s - loss: 6.1061 - main_output_loss: 5.6739 - aux_output_loss: 0.6249 - val_loss: 2.0523 - val_main_output_loss: 1.6846 - val_aux_output_loss: 0.2874\n",
      "Epoch 463/500\n",
      " - 0s - loss: 6.1939 - main_output_loss: 5.7634 - aux_output_loss: 0.6101 - val_loss: 2.0665 - val_main_output_loss: 1.6956 - val_aux_output_loss: 0.3093\n",
      "Epoch 464/500\n",
      " - 0s - loss: 6.0325 - main_output_loss: 5.6049 - aux_output_loss: 0.6083 - val_loss: 2.0225 - val_main_output_loss: 1.6488 - val_aux_output_loss: 0.3350\n",
      "Epoch 465/500\n",
      " - 0s - loss: 6.4199 - main_output_loss: 5.9884 - aux_output_loss: 0.6286 - val_loss: 1.9487 - val_main_output_loss: 1.5697 - val_aux_output_loss: 0.3624\n",
      "Epoch 466/500\n",
      " - 0s - loss: 6.2669 - main_output_loss: 5.8374 - aux_output_loss: 0.6254 - val_loss: 2.0069 - val_main_output_loss: 1.6354 - val_aux_output_loss: 0.3224\n",
      "Epoch 467/500\n",
      " - 0s - loss: 6.1041 - main_output_loss: 5.6786 - aux_output_loss: 0.6033 - val_loss: 2.0511 - val_main_output_loss: 1.6802 - val_aux_output_loss: 0.3287\n",
      "Epoch 468/500\n",
      " - 0s - loss: 6.0752 - main_output_loss: 5.6484 - aux_output_loss: 0.6216 - val_loss: 2.2303 - val_main_output_loss: 1.8721 - val_aux_output_loss: 0.2747\n",
      "Epoch 469/500\n",
      " - 0s - loss: 6.3518 - main_output_loss: 5.9195 - aux_output_loss: 0.6435 - val_loss: 2.0159 - val_main_output_loss: 1.6416 - val_aux_output_loss: 0.3434\n",
      "Epoch 470/500\n",
      " - 0s - loss: 5.9204 - main_output_loss: 5.4879 - aux_output_loss: 0.6482 - val_loss: 2.0561 - val_main_output_loss: 1.6881 - val_aux_output_loss: 0.3125\n",
      "Epoch 471/500\n",
      " - 0s - loss: 6.1466 - main_output_loss: 5.7155 - aux_output_loss: 0.6447 - val_loss: 2.0313 - val_main_output_loss: 1.6607 - val_aux_output_loss: 0.3237\n",
      "Epoch 472/500\n",
      " - 0s - loss: 6.2997 - main_output_loss: 5.8682 - aux_output_loss: 0.6385 - val_loss: 1.9459 - val_main_output_loss: 1.5714 - val_aux_output_loss: 0.3466\n",
      "Epoch 473/500\n",
      " - 0s - loss: 6.2315 - main_output_loss: 5.8073 - aux_output_loss: 0.6006 - val_loss: 2.0822 - val_main_output_loss: 1.7171 - val_aux_output_loss: 0.2962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/500\n",
      " - 0s - loss: 6.1944 - main_output_loss: 5.7602 - aux_output_loss: 0.6560 - val_loss: 2.0250 - val_main_output_loss: 1.6569 - val_aux_output_loss: 0.3149\n",
      "Epoch 475/500\n",
      " - 0s - loss: 6.0979 - main_output_loss: 5.6714 - aux_output_loss: 0.6124 - val_loss: 1.9860 - val_main_output_loss: 1.6133 - val_aux_output_loss: 0.3355\n",
      "Epoch 476/500\n",
      " - 0s - loss: 5.9777 - main_output_loss: 5.5519 - aux_output_loss: 0.6066 - val_loss: 2.0254 - val_main_output_loss: 1.6599 - val_aux_output_loss: 0.2978\n",
      "Epoch 477/500\n",
      " - 0s - loss: 5.8465 - main_output_loss: 5.4215 - aux_output_loss: 0.6120 - val_loss: 1.9463 - val_main_output_loss: 1.5800 - val_aux_output_loss: 0.3106\n",
      "Epoch 478/500\n",
      " - 0s - loss: 6.0225 - main_output_loss: 5.5990 - aux_output_loss: 0.6121 - val_loss: 2.1190 - val_main_output_loss: 1.7565 - val_aux_output_loss: 0.2873\n",
      "Epoch 479/500\n",
      " - 0s - loss: 6.0003 - main_output_loss: 5.5748 - aux_output_loss: 0.6136 - val_loss: 2.0010 - val_main_output_loss: 1.6338 - val_aux_output_loss: 0.3138\n",
      "Epoch 480/500\n",
      " - 0s - loss: 6.0408 - main_output_loss: 5.6191 - aux_output_loss: 0.6058 - val_loss: 2.2222 - val_main_output_loss: 1.8675 - val_aux_output_loss: 0.2718\n",
      "Epoch 481/500\n",
      " - 0s - loss: 5.9770 - main_output_loss: 5.5518 - aux_output_loss: 0.6269 - val_loss: 1.9595 - val_main_output_loss: 1.5948 - val_aux_output_loss: 0.3193\n",
      "Epoch 482/500\n",
      " - 0s - loss: 5.9366 - main_output_loss: 5.5032 - aux_output_loss: 0.6631 - val_loss: 1.9415 - val_main_output_loss: 1.5785 - val_aux_output_loss: 0.3030\n",
      "Epoch 483/500\n",
      " - 0s - loss: 6.0333 - main_output_loss: 5.6083 - aux_output_loss: 0.6276 - val_loss: 1.9775 - val_main_output_loss: 1.6145 - val_aux_output_loss: 0.3072\n",
      "Epoch 484/500\n",
      " - 0s - loss: 5.9498 - main_output_loss: 5.5200 - aux_output_loss: 0.6450 - val_loss: 1.9502 - val_main_output_loss: 1.5866 - val_aux_output_loss: 0.3004\n",
      "Epoch 485/500\n",
      " - 0s - loss: 5.8131 - main_output_loss: 5.3941 - aux_output_loss: 0.5975 - val_loss: 2.3133 - val_main_output_loss: 1.9641 - val_aux_output_loss: 0.2380\n",
      "Epoch 486/500\n",
      " - 0s - loss: 5.7174 - main_output_loss: 5.2875 - aux_output_loss: 0.6468 - val_loss: 2.1195 - val_main_output_loss: 1.7638 - val_aux_output_loss: 0.2693\n",
      "Epoch 487/500\n",
      " - 0s - loss: 5.7548 - main_output_loss: 5.3381 - aux_output_loss: 0.5951 - val_loss: 2.1296 - val_main_output_loss: 1.7786 - val_aux_output_loss: 0.2640\n",
      "Epoch 488/500\n",
      " - 0s - loss: 5.9733 - main_output_loss: 5.5566 - aux_output_loss: 0.6034 - val_loss: 1.9670 - val_main_output_loss: 1.6124 - val_aux_output_loss: 0.2931\n",
      "Epoch 489/500\n",
      " - 0s - loss: 5.9126 - main_output_loss: 5.4940 - aux_output_loss: 0.6006 - val_loss: 2.0928 - val_main_output_loss: 1.7405 - val_aux_output_loss: 0.2599\n",
      "Epoch 490/500\n",
      " - 0s - loss: 5.9914 - main_output_loss: 5.5623 - aux_output_loss: 0.6611 - val_loss: 2.0579 - val_main_output_loss: 1.7097 - val_aux_output_loss: 0.2636\n",
      "Epoch 491/500\n",
      " - 0s - loss: 6.0135 - main_output_loss: 5.5985 - aux_output_loss: 0.6023 - val_loss: 1.9964 - val_main_output_loss: 1.6422 - val_aux_output_loss: 0.2852\n",
      "Epoch 492/500\n",
      " - 0s - loss: 5.9368 - main_output_loss: 5.5203 - aux_output_loss: 0.6055 - val_loss: 1.9527 - val_main_output_loss: 1.5956 - val_aux_output_loss: 0.2934\n",
      "Epoch 493/500\n",
      " - 0s - loss: 6.0136 - main_output_loss: 5.5939 - aux_output_loss: 0.6147 - val_loss: 2.0492 - val_main_output_loss: 1.6923 - val_aux_output_loss: 0.2818\n",
      "Epoch 494/500\n",
      " - 0s - loss: 5.9016 - main_output_loss: 5.4851 - aux_output_loss: 0.5963 - val_loss: 1.9585 - val_main_output_loss: 1.5890 - val_aux_output_loss: 0.3552\n",
      "Epoch 495/500\n",
      " - 0s - loss: 5.9398 - main_output_loss: 5.5166 - aux_output_loss: 0.6240 - val_loss: 2.4084 - val_main_output_loss: 2.0667 - val_aux_output_loss: 0.2085\n",
      "Epoch 496/500\n",
      " - 0s - loss: 5.8340 - main_output_loss: 5.4169 - aux_output_loss: 0.5966 - val_loss: 2.0110 - val_main_output_loss: 1.6467 - val_aux_output_loss: 0.3342\n",
      "Epoch 497/500\n",
      " - 0s - loss: 5.9710 - main_output_loss: 5.5469 - aux_output_loss: 0.6282 - val_loss: 2.1144 - val_main_output_loss: 1.7516 - val_aux_output_loss: 0.3014\n",
      "Epoch 498/500\n",
      " - 0s - loss: 5.9411 - main_output_loss: 5.5183 - aux_output_loss: 0.6232 - val_loss: 2.0542 - val_main_output_loss: 1.6952 - val_aux_output_loss: 0.3033\n",
      "Epoch 499/500\n",
      " - 0s - loss: 5.6594 - main_output_loss: 5.2407 - aux_output_loss: 0.6080 - val_loss: 1.9691 - val_main_output_loss: 1.6069 - val_aux_output_loss: 0.2998\n",
      "Epoch 500/500\n",
      " - 0s - loss: 5.7406 - main_output_loss: 5.3159 - aux_output_loss: 0.6284 - val_loss: 1.9780 - val_main_output_loss: 1.6184 - val_aux_output_loss: 0.2994\n",
      "Without dropout = TrainRMSE : 1.0568593720491635 TestRMSE : 1.657552068493805\n",
      "With dropout = TrainRMSE : 1.1026677260264754 TestRMSE : 1.6858506902427601\n",
      "Without dropout : Test Incon = 0.0  Train Incon = 0.0\n",
      "With dropout Inconsistency of sample mean: Test Incon = 0.030135135135135136  Train Incon = 0.034833759590792844\n",
      "With dropout Inconsistency of all samples: Test Incon = 0.2435243243243243  Train Incon = 0.2841897698209719\n",
      "(100, 740, 50)\n",
      "(740, 50, 2)\n",
      "(100, 391, 50)\n",
      "(391, 50, 2)\n",
      "Train p-values : 0.33321739130434785\n",
      "Test p-values : 0.23715648648648652\n",
      "sample mean shape (740, 50)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean P-value = 0.5172983847109639\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\t# Main Function\n",
    "    #tr_frac_range = [50,25,20,15,10,5];\n",
    "    tr_frac_range=[50];\n",
    "    #tr_frac=50;\n",
    "    val_frac = 0.1;\n",
    "    patience_val = 200;\n",
    "    num_epochs = 500;\n",
    "    batch_size = 20;\n",
    "    #lstm_nodes_range = [4,8,16,25];\n",
    "    lstm_nodes=8;\n",
    "    #feedforward_nodes_range = [3,5,7,10];\n",
    "    feedforward_nodes=5;\n",
    "    mask_value = 0;\n",
    "    drop_frac = 0.3;\n",
    "    #drop_frac_range=[0.2,0.3,0.5];\n",
    "    lstm_bias = 1;\n",
    "    #n_nodes_range=[5,10];\n",
    "    n_nodes=5;\n",
    "    use_GLM=1;\n",
    "    use_temporal_feature=1;\n",
    "    usePad = 0;\n",
    "    iter_range=np.arange(1);\n",
    "    lamda_reg=0.05;\n",
    "    #iter_range=[1];\n",
    "    #iteration=0;  \n",
    "    \n",
    "    for iteration in iter_range:\n",
    "       for tr_frac in tr_frac_range:\n",
    "            PGA_LSTM_train_test(\n",
    "                          iteration,\n",
    "                          usePad,\n",
    "                          tr_frac,\n",
    "                          val_frac,\n",
    "                          patience_val,\n",
    "                          num_epochs,\n",
    "                          batch_size,\n",
    "                          lstm_nodes,\n",
    "                          feedforward_nodes,\n",
    "                          mask_value,\n",
    "                          drop_frac,\n",
    "                          lstm_bias,\n",
    "                          n_nodes,\n",
    "                          use_GLM,\n",
    "                          use_temporal_feature,\n",
    "                          lamda_reg\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pga_lstm.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
